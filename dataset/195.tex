\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{url}

\usepackage{amsmath}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{subfigure}
\usepackage{array}
\usepackage{tabularx}
\usepackage{multirow}


\newcommand{\bfx}{{\textbf{x}}}
\newcommand{\bfv}{{\textbf{v}}}
\newcommand{\bfu}{{\textbf{u}}}
\newcommand{\bfw}{{\textbf{w}}}
\newcommand{\bfy}{{\textbf{y}}}
\newcommand{\bfg}{{\textbf{g}}}
\newcommand{\bft}{{\textbf{t}}}
\newcommand{\bfmu}{{\boldsymbol{\mu}}}
\newcommand{\bfpi}{{\boldsymbol{\pi}}}
\newcommand{\bfiota}{{\boldsymbol{\iota}}}
\newcommand{\bfalpha}{{\boldsymbol{\alpha}}}
\newcommand{\bfbeta}{{\boldsymbol{\beta}}}
\newcommand{\bfphi}{{\boldsymbol{\phi}}}
\newcommand{\bfvarphi}{{\boldsymbol{\varphi}}}
\newcommand{\mathbbK}{{\mathbb{K}}}

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}

\mainmatter  % start of an individual contribution

\title{Image tag completion by local learning}

\titlerunning{Image tag completion by local learning}

\author{Jingyan Wang$^{1,2,3}$
\and
Yihua Zhou$^4$
\and
Haoxiang Wang$^5$
\and
Xiaohong Yang$^6$
\and
Feng Yang$^6$
\and
Austin Peterson$^7$
}

\authorrunning{J. Wang, et al.}

\institute{
National Time Service Center, Chinese Academy of Sciences, Xi' an, Shaanxi 710600 , China\\
\email{jingbinwang1@outlook.com}
\and
Graduate University of Chinese Academy of Sciences, Beijing 100049, China
\and
Provincial Key Laboratory for Computer Information Processing Technology, Soochow University Suzhou 215006, China
\and
Department of mechanical engineering and mechanics, Lehigh University, Bethlehem, PA 18015, US
\and
Department of Electrical and Computer Engineering, Cornell University, Ithaca, NY 14850, USA
\and
College of  Computer Science and Technology, Shandong University of Finance and Economics, Jinan 250014, China
\and
Electrical and Computer Engineering Department, The University of Texas at San Antonio, San Antonio, TX, 78249, USA\\
\email{austin.peterson1@outlook.com}
}

\maketitle


\begin{abstract}
The problem of tag completion is to learn the missing tags of an image. In this paper, we propose to learn a tag scoring vector for each image by local linear learning. A local linear function is used in the neighborhood of each image to predict the tag scoring vectors of its neighboring images. We construct a unified objective function for the learning of both tag scoring vectors and local linear function parameters. In the objective, we impose the learned tag scoring vectors to be consistent with the known associations to the tags of each image, and also minimize the prediction error of each local linear function, while reducing the complexity of each local function. The objective function is optimized by an alternate optimization strategy and gradient descent methods in an iterative algorithm. We compare the proposed algorithm against different state-of-the-art tag completion methods, and the results show its advantages.
\keywords{Image tagging,
Tag completion,
Local learning,
Gradient descent}
\end{abstract}

\section{Introduction}

Recently, social network has been a popular tool to share images. When a social network user uploads an image, the image is usually associated with a tag/ keyword which is used to describe the semantic content of this image. The tags provided by the users are usually incomplete. Zhang et al. designed and implemented a fast motion detection mechanism for multimedia data on mobile and embedded environment \cite{zhang2014lucas}. Recently, the problem image tag completion is proposed in the computer vision and machine learning communities to learn the missing tags of images \cite{Wu2013716,Lin20131618,Lin201442,Feng2014424,Xia2014,liu2015supervised,wang2015representing}. This problem is defined as the problem of complete the missing elements of a tag vector of a given image automatically.

In this paper, we investigate the problem of image tag completion, and proposed a novel and effective algorithm for this problem based on local linear learning.
We propose a novel and effective tag completion method. Instead of completing the missing tag association elements of each image, we introduce a tag scoring vector to indicate the scores of assigning the image to the tags in a given tag set. We propose to study the tag scoring vector learning problem in the neighborhood of each image. For each image in the neighborhood, we propose to learn a linear function to predict a tag scoring vector from a visual feature vector of its corresponding image feature. We propose to minimize the perdition error measure by the squared $\ell_2$ norm distance over each neighborhood, and also minimize the squared $\ell_2$ norm of the linear function parameters. Besides the local linear learning, we also proposed to regularize the learning of tag scoring vectors by the available tags of each image. We construct a unified objective function to learn both the tag scoring vectors and the  local linear functions. We develop an iterative algorithm to optimize the proposed problem. In each iteration of this algorithm, we update the tag scoring vectors and the local linear function parameters alternately.

This rest parts of  paper are organized as follows: in section \ref{sec:method}, we introduced the proposed method. In section \ref{sec:exp}, we evaluate the proposed methods on some benchmark data sets. In section \ref{sec:conclusion}, the paper is concluded with future works.

\section{Proposed method}
\label{sec:method}


We assume that we have a data set of $n$ images, and their visual feature vectors are $\bfx_i|_{i=1}^n$, where $\bfx_i \in \mathbb{R}^d$ is the $d$-dimensional feature vector of the $i$-th image. We also assume that we have a set of $m$ unique tags, and a tag vector $\widehat{\bft}_i =[\widehat{t}_{i1},\cdots, \widehat{t}_{im}]^\top \in \{+1,-1\}^m$ for the $i$-th image $\bfx_i$, where
$\widehat{t}_{ij} =
+1$ if~the~$j$-th~tag~is~assigned ~to~the~$i$-th~image, and $-1$, otherwise. In real-world applications, the tag vector of an image $\bfx_i$ is usually incomplete, i.e., some elements of $\widehat{\bft}_i$ are missing. We define a vector $\bfv_i = [v_{i1},\cdots,v_{im}]\in \{1,0\}^m$, where $v_{ij} = 1$ if $\widehat{t}_{ij}$ is available, and $0$ if $\widehat{t}_{ij}$ is missing. We propose to learn a tag scoring vector $\bft_i = [t_{i1}, \cdots,t_{im}]\in \mathbb{R}^m$, where $t_{ij}$ is the score of assigning the $j$-th tag to the $i$-th image.

The set of the $\kappa$ nearest neighbor of each image $\bfx_i$ is denoted as $\mathcal{N}_i$, and we assume that the tag scoring vector $\bft_j$ of a image $\bfx_j \in \mathcal{N}_i$ can be predicted from its visual feature vector $\bfx_j$ using a local linear function $f_i(\bfx_j)$,

\begin{equation}
\begin{aligned}
\bft_j  \leftarrow f_i(\bfx_j)=W_i \bfx_j , ~\forall~j:\bfx_j\in \mathcal{N}_i,
\end{aligned}
\end{equation}
where $W_i\in \mathbb{R}^{m\times d}$ is the parameter of the local linear function. To learn the tag scoring vector and the local function parameters, we propose the following minimization problem,

\begin{equation}
\label{equ:obj3}
\begin{aligned}
\min_{\bft_i|_{i=1}^n,W_i|_{i=1}^n}
&
\left \{
g(\bft_i|_{i=1}^n,W_i|_{i=1}^n)
\vphantom{\sum_{j:v_{ij}=1}}
 =
\sum_{i=1}^n
\left (
\sum_{j:\bfx_j\in \mathcal{N}_i} \| \bft_j - W_i \bfx_j\|_2^2 + \alpha \|W_i\|_2^2
\right.\right.
\\
&\left .\left .
\vphantom{\sum_{i}^2}
+\beta(\bft_i - \widehat{\bft}_i)^\top diag(\bfv_i) (\bft_i - \widehat{\bft}_i)
\right )
\right \}
\end{aligned}
\end{equation}
where $\alpha$ and $\beta$ are tradeoff parameters. The objective function $g(\bft_i|_{i=1}^n,W_i|_{i=1}^n)$ in (\ref{equ:obj3}) is a summarization of three terms over all the images in the data set. The first term, $\sum_{j:\bfx_j\in \mathcal{N}_i} \| \bft_j - W_i \bfx_j\|_2^2$, is the prediction error term of the local linear predictor over the neighborhood of each image. The second, $\|W_i\|_2^2$, is to reduce the complexity of the local linear predictor. The last term, $(\bft_i - \widehat{\bft}_i)^\top diag(\bfv_i) (\bft_i - \widehat{\bft}_i)$, is a regularization term to regularize the learning of tag scoring vectors by the incomplete tag vectors, so that the available tags are respected.
To optimize the minimization problem in (\ref{equ:obj3}), we propose to use the alternate optimization strategy \cite{Huang2015233,Liu2015188} in an iterative algorithm.

\begin{itemize}
\item \textbf{Optimization of $\bft_i|_{i=1}^n$}
In each iteration, we optimize $\bft_i|_{i=1}^n$ one by one, and the minimization of (\ref{equ:obj3}) with respect to $\bft_i$ can be achieved with the following gradient descent update rule,

\begin{equation}
\label{equ:ti}
\begin{aligned}
\bft_i^{new} = \bft_i^{old} - \eta \nabla_{\bft_i}g
(\bft_j|_{j=1}^n,W_i|_{i=1}^n)
|_{\bft_i=\bft_i^{old}},
\end{aligned}
\end{equation}
where $\nabla_{\bft_i}g(\bft_j|_{j=1}^n,W_i|_{i=1}^n)$ is the sub-gradient function of $g(\bft_j|_{j=1}^n,W_i|_{i=1}^n)$, with respect to $\bft_i$,

\begin{equation}
\label{equ:gradient}
\begin{aligned}
\nabla_{\bft_i}g
(\bft_j|_{j=1}^n,W_i|_{i=1}^n)
= 2 \sum_{k:\bfx_i \in \mathcal{N}_k} (\bft_i - W_k \bfx_i) + 2\beta diag(\bfv_i) (\bft_i - \widehat{\bft}_i),
\end{aligned}
\end{equation}
and $\eta$ is the descent step.

\item \textbf{Optimization of $W_i|_{i=1}^n$}
In each iteration, we also optimized $W_i|_{i=1}^n$ one by one. When $W_i$ is optimized, $W_j|_{j\neq i}$ are fixed. Gradient descent method is also employed to update $W_i$ to minimize the objective in (\ref{equ:obj3}),

\begin{equation}
\label{equ:w1}
\begin{aligned}
W_i^{new} = W_i^{old} - \eta \nabla_{W_i} g(\bft_i|_{i=1}^n, W_i|_{i=1}^n)|_{W_i=W_i^{old}},
\end{aligned}
\end{equation}
where $\nabla_{W_i} g(\bft_i|_{i=1}^n, W_i|_{i=1}^n)$ is the sub-gradient function with respect to $W_i$,

\begin{equation}
\label{equ:w2}
\begin{aligned}
\nabla_{W_i} g(\bft_i|_{i=1}^n, W_i|_{i=1}^n)
= 2 \sum_{j:\bfx_j \in \mathcal{N}_i} (\bft_j - W_i \bfx_j) \bfx_j^\top + 2 \beta W_i.
\end{aligned}
\end{equation}

\end{itemize}


\section{Experiments}
\label{sec:exp}


\subsection{Setup}

In the experiments, we used two publicly accessed image-tag data sets, which are Corel5k data set \cite{Zhang2012838,Huang20103376,Wang20091643} and IAPR TC12 data set \cite{Zhang20151658,Li20132700,Zhang2012838}.
In the Corel5k data set, there are 4,918 images, and 260 tages. We extract density feature, Harris shift feature, Harris Hue feature, RGB color feature, and HSV color feature as visual features for each image. Moreover, we remove  40\% of the elements of the tag vectors to make the incomplete image tag vectors. In the IAPR TC12 data set, there are 19,062 images, and 291 tags. We also remove 40\% elements of the tag elements to construct the incomplete tag vectors.
To evaluate the tag completion performances, we used the recall-precision curve as performance measure.
We also use mean average precision (MAP) as a single performance measure.

\subsection{Results}

We compared the proposed method to several state-of-the-art tag completion methods, including tag matrix completion (TMC) \cite{Wu2013716}, linear sparse reconstructions (LSR) \cite{Lin201442}, tag completion by noisy matrix recovery (TCMR)\cite{Feng2014424}, and tag completion via NMF (TC-NMF) \cite{Xia2014}. The experimental result on two data sets are given in Fig. \ref{fig:Corel5k} and Fig. \ref{fig:IAPR}. From these figures, we can see that the proposed method LocTC performs best. Its recall-precision curve is closer to the top-right corner than any other methods, and its MAP is also higher than MAPs of other methods.

\begin{figure}[!htb]
\centering
\subfigure[Recall-precision curve]{
\includegraphics[width=0.45\textwidth]{FigCorel_Rec150129}}
\subfigure[MAP]{
\includegraphics[width=0.45\textwidth]{FigCorel_MAP150129}}
\caption{Results of comparison to state-of-the-art methods on Corel5k data set}
\label{fig:Corel5k}
\end{figure}


\begin{figure}[!htb]
\centering
\subfigure[Recall-precision curve]{
\includegraphics[width=0.45\textwidth]{FigIAPR_Rec150129}}
\subfigure[MAP]{
\includegraphics[width=0.45\textwidth]{FigIAPR_MAP150129}}
\caption{Results of comparison to state-of-the-art methods on IAPR TC12 data set}
\label{fig:IAPR}
\end{figure}

In this section, we will study the sensitivity of the proposed algorithm to the two parameters, $\alpha$ and $\beta$. The curves of $\alpha$ and $\beta$ on different data sets are given in Fig. \ref{fig:Corel_alpah} and Fig. \ref{fig:IAPR_alpah}. From these figures, we can see that the performances are stable to different valuse of  both $\alpha$ and $\beta$.

\begin{figure}[!htb]
  \centering
\subfigure[$\alpha$]{
\includegraphics[width=0.45\textwidth]{FigCorel_alpha150129}}
\subfigure[$\beta$]{
\includegraphics[width=0.45\textwidth]{FigCorel_beta150129}}
\\
\caption{Parameter sensitivity curve on Corel5k data set.}
\label{fig:Corel_alpah}
\end{figure}


\begin{figure}[!htb]
  \centering
\subfigure[$\alpha$]{
\includegraphics[width=0.45\textwidth]{FigIAPR_alpha150129}}
\subfigure[$\beta$]{
\includegraphics[width=0.45\textwidth]{FigIAPR_beta150129}}
\\
\caption{Parameter sensitivity curve on IAPR TC12 data set.}
\label{fig:IAPR_alpah}
\end{figure}



\section{Conclusion and future works}
\label{sec:conclusion}

In this paper, we study the problem of tag completion, and proposed a novel algorithm for this problem. We proposed to learn the tags of images in the neighborhood of each image. A local linear function is designed to predict the tag scoring vectors of images in each neighborhood, and the prediction function parameter is learned jointly with the tag scoring vectors. The proposed method is compared to state-of-the-art tag completion algorithms, and the results show that the proposed algorithm outperforms the compared methods. In the future, we will study how to incorporate these connections into our model and learn more effective tags. In this paper, we used one single local function for each neighborhood, and in the future, we will use more than than regularization to regularized the learning of tags \cite{wang2012multiplegraph,wang2013multiple}, such as usage of wavelet functions to construct the local function \cite{liu2012wavpeak}. Moreover, correntropy can also be considered as a alternative loss function to construct the local learning problem \cite{wang2013non,Xing2014483,Li2015850,Zhang2015120,wang2014effective}. In the future, we also plan to extend the proposed algorithm for completion of tags of large scale image data set by using high performance computing technology \cite{zhou2013exploring,wang2015towards,zhang2011gpapriori,zhang2013accelerating,zhang2011frequent,zhang2013fpga,gao2014sparse,zhang2014lucas,li2013zht,zhao2014fusionfs,li2013distributed,wang2013using,wang2014optimizing,wang2014next}, and completion of tags of gene/protein functions of bioinformatics problems \cite{hu2009improving,zhang2009bayesian,zhang2010bioinformatics,hu2009improving,wang2015multiple,wang2015supervised}.



\begin{thebibliography}{10}
\providecommand{\url}[1]{{#1}}
\providecommand{\urlprefix}{URL }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{DOI~\discretionary{}{}{}#1}\else
  \providecommand{\doi}{DOI~\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi

\bibitem{Feng2014424}
Feng, Z., Feng, S., Jin, R., Jain, A.: Image tag completion by noisy matrix
  recovery.
\newblock Lecture Notes in Computer Science (including subseries Lecture Notes
  in Artificial Intelligence and Lecture Notes in Bioinformatics) \textbf{8695
  LNCS}(PART 7), 424--438 (2014)

\bibitem{gao2014sparse}
Gao, Y., Zhang, F., Bakos, J.D.: Sparse matrix-vector multiply on the keystone
  ii digital signal processor.
\newblock In: High Performance Extreme Computing Conference (HPEC), 2014 IEEE,
  pp. 1--6 (2014)

\bibitem{hu2009improving}
Hu, J., Zhang, F.: Improving protein localization prediction using amino acid
  group based physichemical encoding.
\newblock In: Bioinformatics and Computational Biology, pp. 248--258 (2009)

\bibitem{Huang2015233}
Huang, S., Ma, Z., Wang, F.: A multi-objective design optimization strategy for
  vertical ground heat exchangers.
\newblock Energy and Buildings \textbf{87}, 233--242 (2015)

\bibitem{Huang20103376}
Huang, Y., Liu, Q., Zhang, S., Metaxas, D.: Image retrieval via probabilistic
  hypergraph ranking.
\newblock In: Proceedings of the IEEE Computer Society Conference on Computer
  Vision and Pattern Recognition, pp. 3376--3383 (2010)

\bibitem{Li2015850}
Li, L., Yang, J., Xu, Y., Qin, Z., Zhang, H.: Documents clustering based on
  max-correntropy nonnegative matrix factorization.
\newblock pp. 850--855 (2015)

\bibitem{li2013distributed}
Li, T., Zhou, X., Brandstatter, K., Raicu, I.: Distributed key-value store on
  hpc and cloud systems.
\newblock In: 2nd Greater Chicago Area System Research Workshop (GCASR) (2013)

\bibitem{li2013zht}
Li, T., Zhou, X., Brandstatter, K., Zhao, D., Wang, K., Rajendran, A., Zhang,
  Z., Raicu, I.: Zht: A light-weight reliable persistent dynamic scalable
  zero-hop distributed hash table.
\newblock In: Parallel \& Distributed Processing (IPDPS), 2013 IEEE 27th
  International Symposium on, pp. 775--787 (2013)

\bibitem{Li20132700}
Li, Z., Liu, J., Xu, C., Lu, H.: Mlrank: Multi-correlation learning to rank for
  image annotation.
\newblock Pattern Recognition \textbf{46}(10), 2700--2710 (2013)

\bibitem{Lin201442}
Lin, Z., Ding, G., Hu, M., Lin, Y., Sam~Ge, S.: Image tag completion via
  dual-view linear sparse reconstructions.
\newblock Computer Vision and Image Understanding \textbf{124}, 42--60 (2014)

\bibitem{Lin20131618}
Lin, Z., Ding, G., Hu, M., Wang, J., Ye, X.: Image tag completion via
  image-specific and tag-specific linear sparse reconstructions.
\newblock In: Proceedings of the IEEE Computer Society Conference on Computer
  Vision and Pattern Recognition, pp. 1618--1625 (2013)

\bibitem{Liu2015188}
Liu, L., Li, H., Xue, Y., Liu, W.: Reactive power compensation and optimization
  strategy for grid-interactive cascaded photovoltaic systems.
\newblock IEEE Transactions on Power Electronics \textbf{30}(1), 188--202
  (2015)

\bibitem{liu2015supervised}
Liu, X., Wang, J., Yin, M., Edwards, B., Xu, P.: Supervised learning of sparse
  context reconstruction coefficients for data representation and
  classification.
\newblock Neural Computing and Applications  (2015)

\bibitem{liu2012wavpeak}
Liu, Z., Abbas, A., Jing, B.Y., Gao, X.: Wavpeak: picking nmr peaks through
  wavelet-based smoothing and volume-based filtering.
\newblock Bioinformatics \textbf{28}(7), 914--920 (2012)

\bibitem{Wang20091643}
Wang, C., Yan, S., Zhang, L., Zhang, H.J.: Multi-label sparse coding for
  automatic image annotation.
\newblock pp. 1643--1650 (2009)

\bibitem{wang2014effective}
Wang, H., Wang, J.: An effective image representation method using kernel
  classification.
\newblock In: 2014 IEEE 26th International Conference on Tools with Artificial
  Intelligence (ICTAI 2014), pp. 853--858 (2014)

\bibitem{wang2015multiple}
Wang, J., Wang, H., Zhou, Y., McDonald, N.: Multiple kernel multivariate
  performance learning using cutting plane algorithm.
\newblock In: Systems, Man and Cybernetics (SMC), 2015 IEEE International
  Conference on. IEEE (2015)

\bibitem{wang2015supervised}
Wang, J., Zhou, Y., Duan, K., Wang, J.J.Y., Bensmail, H.: Supervised
  cross-modal factor analysis for multiple modal data classification.
\newblock In: Systems, Man and Cybernetics (SMC), 2015 IEEE International
  Conference on. IEEE (2015)

\bibitem{wang2015representing}
Wang, J., Zhou, Y., Yin, M., Chen, S., Edwards, B.: Representing data by sparse
  combination of contextual data points for classification.
\newblock In: Advances in Neural Networks--ISNN 2015. Springer (2015)

\bibitem{wang2012multiplegraph}
Wang, J.J.Y., Bensmail, H., Gao, X.: Multiple graph regularized protein domain
  ranking.
\newblock BMC bioinformatics \textbf{13}(1), 307 (2012)

\bibitem{wang2013multiple}
Wang, J.J.Y., Bensmail, H., Gao, X.: Multiple graph regularized nonnegative
  matrix factorization.
\newblock Pattern Recognition \textbf{46}(10), 2840--2847 (2013)

\bibitem{wang2013non}
Wang, J.J.Y., Wang, X., Gao, X.: Non-negative matrix factorization by
  maximizing correntropy for cancer clustering.
\newblock BMC bioinformatics \textbf{14}(1), 107 (2013)

\bibitem{wang2013using}
Wang, K., Kulkarni, A., Zhou, X., Lang, M., Raicu, I.: Using simulation to
  explore distributed key-value stores for exascale system services.
\newblock In: 2nd Greater Chicago Area System Research Workshop (GCASR) (2013)

\bibitem{wang2014next}
Wang, K., Zhou, X., Chen, H., Lang, M., Raicu, I.: Next generation job
  management systems for extreme-scale ensemble computing.
\newblock In: Proceedings of the 23rd international symposium on
  High-performance parallel and distributed computing, pp. 111--114 (2014)

\bibitem{wang2014optimizing}
Wang, K., Zhou, X., Li, T., Zhao, D., Lang, M., Raicu, I.: Optimizing load
  balancing and data-locality with data-aware scheduling.
\newblock In: Big Data (Big Data), 2014 IEEE International Conference on, pp.
  119--128 (2014)

\bibitem{wang2015towards}
Wang, K., Zhou, X., Qiao, K., Lang, M., McClelland, B., Raicu, I.: Towards
  scalable distributed workload manager with monitoring-based weakly consistent
  resource stealing.
\newblock In: Proceedings of the 24rd international symposium on
  High-performance parallel and distributed computing, pp. 219--222 (2015)

\bibitem{Wu2013716}
Wu, L., Jin, R., Jain, A.: Tag completion for image retrieval.
\newblock IEEE Transactions on Pattern Analysis and Machine Intelligence
  \textbf{35}(3), 716--727 (2013)

\bibitem{Xia2014}
Xia, Z., Feng, X., Peng, J., Wu, J., Fan, J.: A regularized optimization
  framework for tag completion and image retrieval.
\newblock Neurocomputing  (2014)

\bibitem{Xing2014483}
Xing, H.J., Ren, H.R.: Regularized correntropy criterion based feature
  extraction for novelty detection.
\newblock Neurocomputing \textbf{133}, 483--490 (2014)

\bibitem{zhang2014lucas}
Zhang, F., Gao, Y., Bakos, J.D.: Lucas-kanade optical flow estimation on the ti
  c66x digital signal processor.
\newblock In: High Performance Extreme Computing Conference (HPEC), 2014 IEEE,
  pp. 1--6 (2014)

\bibitem{zhang2009bayesian}
Zhang, F., Hu, J.: Bayesian classifier for anchored protein sorting discovery.
\newblock In: Bioinformatics and Biomedicine, 2009. BIBM'09. IEEE International
  Conference on, pp. 424--428 (2009)

\bibitem{zhang2010bioinformatics}
Zhang, F., Hu, J.: Bioinformatics analysis of physicochemical properties of
  protein sorting signals  (2010)

\bibitem{zhang2011gpapriori}
Zhang, F., Zhang, Y., Bakos, J.: Gpapriori: Gpu-accelerated frequent itemset
  mining.
\newblock In: Cluster Computing (CLUSTER), 2011 IEEE International Conference
  on, pp. 590--594 (2011)

\bibitem{zhang2013accelerating}
Zhang, F., Zhang, Y., Bakos, J.D.: Accelerating frequent itemset mining on
  graphics processing units.
\newblock The Journal of Supercomputing \textbf{66}(1), 94--117 (2013)

\bibitem{Zhang2012838}
Zhang, S., Huang, J., Li, H., Metaxas, D.: Automatic image annotation and
  retrieval using group sparsity.
\newblock IEEE Transactions on Systems, Man, and Cybernetics, Part B:
  Cybernetics \textbf{42}(3), 838--849 (2012)

\bibitem{Zhang20151658}
Zhang, X., Liu, C.: Image annotation based on feature fusion and semantic
  similarity.
\newblock Neurocomputing \textbf{149}(PC), 1658--1671 (2015)

\bibitem{zhang2011frequent}
Zhang, Y., Zhang, F., Bakos, J.: Frequent itemset mining on large-scale shared
  memory machines.
\newblock In: Cluster Computing (CLUSTER), 2011 IEEE International Conference
  on, pp. 585--589 (2011)

\bibitem{zhang2013fpga}
Zhang, Y., Zhang, F., Jin, Z., Bakos, J.D.: An fpga-based accelerator for
  frequent itemset mining.
\newblock ACM Transactions on Reconfigurable Technology and Systems (TRETS)
  \textbf{6}(1), 2 (2013)

\bibitem{Zhang2015120}
Zhang, Z., Chen, J.: Correntropy based data reconciliation and gross error
  detection and identification for nonlinear dynamic processes.
\newblock Computers and Chemical Engineering \textbf{75}, 120--134 (2015)

\bibitem{zhao2014fusionfs}
Zhao, D., Zhang, Z., Zhou, X., Li, T., Wang, K., Kimpe, D., Carns, P., Ross,
  R., Raicu, I.: Fusionfs: Toward supporting data-intensive scientific
  applications on extreme-scale high-performance computing systems.
\newblock In: Big Data (Big Data), 2014 IEEE International Conference on, pp.
  61--70 (2014)

\bibitem{zhou2013exploring}
Zhou, X., Chen, H., Wang, K., Lang, M., Raicu, I.: Exploring distributed
  resource allocation techniques in the slurm job management system.
\newblock Illinois Institute of Technology, Department of Computer Science,
  Technical Report  (2013)

\end{thebibliography}


\end{document}



