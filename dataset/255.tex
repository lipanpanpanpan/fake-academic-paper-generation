\documentclass[12pt,twoside]{article}
\usepackage{setspace,graphicx,natbib,bm,fancyhdr}
\usepackage{amsmath}
\usepackage{amsmath,amsthm,amssymb,latexsym}
\usepackage{color}
\usepackage{graphicx}

\usepackage{authblk}
\renewcommand{\baselinestretch}{1.2}
\setlength{\topmargin}{-0.2in}
\setlength{\textwidth}{6in}
\setlength{\textheight}{8.5in}
\setlength{\oddsidemargin}{0.25in}
\setlength{\evensidemargin}{0.25in}
\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\bl}{\color{blue}}
\newcommand{\mbv}[1]{\mbox{\boldmath$#1$\unboldmath}}
\newcommand{\rf}{\vskip .1in\par\sloppy\hangindent=1pc\hangafter=1
                 \noindent}
\newcommand{\slas}[1]{\mbox{${{#1} \!\!\! /}$}}
\raggedbottom

\begin{document}
\title{\bf A Neural Markovian Concurrent Image Labeling Algorithm}
\author{John Mashford\footnote{corresponding author, e-mail: mashford@unimelb.edu.au, tel.: +61 448 800 171}  \\
University of Melbourne \\
School of Mathematics and Statistics \\
Parkville, Vic. 3010, Australia}
\date{\today}
\maketitle

\begin{abstract}

This paper describes the MCV image labeling algorithm which is a (semi-) hierarchical algorithm commencing with a
partition made up of single pixel regions and merging regions or subsets of regions using a Markov random field (MRF) image
model. It is an example of a general approach to computer vision called concurrent vision in which the operations of image
segmentation and image classification are carried out concurrently. The output of the MCV algorithm can be a simple
segmentation partition or a sequence of partitions which can provide useful information to higher level vision systems. In the
case of an autoregressive Gaussian MRF the evaluation of sub-images for homogeneity is computationally inexpensive and
may be effected by a hardwired feed-forward neural network. The merge operation of the algorithm is massively parallelizable. While being applicable to images (i.e. 2D signals), the algorithm is equally applicable to 1D signals (e.g. speech) or 3D signals (e.g. video sequences)

Keywords: hierarchical, Markov random fields, region growing, partitioning, segmentation

\end{abstract}

\section{Introduction}

The concurrent vision approach formulated by Mashford {\em et al.} in [1,2] is based on the idea
that image segmentation and classification can be carried out concurrently using a hierarchical
algorithm which generates a multiresolution partition tree. A particular instance of this
approach utilizing Markov random fields (MRFs) to define a criterion for region homogeneity
was described in [3] and called Markov concurrent vision (MCV).

MRFs have
been used for many years in computer vision applications [4,5,6]. Dawoud and Netchaev [6]
proposed a merge-based algorithm using MRFs for segmentation commencing with a partition
obtained by watershed algorithm over-segmentation and using the Canny edge detector
to guide the merge process. Alpert {\em et al.} [7] and Sharon {\em et al.} [8] describe an approach which
utilizes hierarchical aggregation from a partition formed from single-pixel regions as in [1].
Approaches to concurrent segmentation and classification are described in [9,10].

The present paper describes a modification and improvement [11] of the MCV algorithm,
which may be called sequential MCV, or simply MCV. The improved algorithm is faster and
more effective than the original MCV algorithm.
The MCV algorithm outputs a sequence of partitions (or superpixel sets [5]) which may be
useful to higher level vision systems because of their dynamic multiresolution scene representation
and also because their structure, which is more elaborate than a simple segmentation,
allows incremental processing of video sequences. It provides greater functionality for higher level
vision systems and provides a natural framework for generating high-level object representations
at all scales and for implementing the content-based scalability requirement of the
MPEG video standard.

The second section of this paper describes the (sequential) MCV algorithm, while Section 3
describes the MRF image evaluation criterion used by MCV. Some results of applying the algorithm
are presented in section 4 and the paper concludes with the final section.

\section{Hierarchical representation of pixel-based low level vision systems}

The simplest low-level vision system is formed by thresholding intensity and then carrying
out connected component labeling. More generally, a low level vision system may operate by
means of a pixel classifier $\gamma : X \rightarrow C$ where $X = \{1, \ldots, m\} \times \{1, \ldots, n\}$ is the image lattice and $C
\neq \emptyset$ is a finite set of classification labels e.g. for a simple foreground/background classification
$C = \{0,1\}$. The set of all regions of interest
(ROIs) or objects in the image is taken to be
\begin{equation}
\Pi = \cup\{\mbox{Comp}(\gamma^{-1}(c)) : c\in C\},
\end{equation}
where, for any $S \subset X$, Comp$(S)$ denotes the set of connected components of $S$. Thus the objects
in the image are taken to be the connected components of the sets of constant classification by
$\gamma$. The classifier $\gamma$ may act only on the pixel values of its argument or, more generally, it may
act on features extracted from a neighborhood of its argument. Since $\Pi_c = \mbox{Comp}(\gamma^{-1}(c))$ is a
partition of $\gamma^{-1}(c)$ for all $c \in C$ and $\gamma^{-1}(C) = \cup\{\gamma^{-1}(c) : c \in C\} = X$ it follows that $\Pi$ is a partition of $X$.

We may describe a hierarchical algorithm for generating $\Pi$ by describing a hierarchical algorithm
for generation of Comp$(S)$ for all $S \subset X$ and then applying the algorithm to $\gamma^{-1}(c)$ for all $c\in C$. For any set $\Omega$ let $P(\Omega)$ denote the power set of $\Omega$, thus $P(\Omega)$ (also denoted as $2^{\Omega}$) is the collection of all subsets of $\Omega$. Also let $P^2(\Omega) = P(P(W))$. For $S \subset X$ define $S_0(x) = S \cap (x + W_0)$ where $W_0 \subset {\bf Z}^2$ (${\bf Z}$ denotes the integers) is the neighborhood of $0$ defining the neighbourhood relation
with respect to which connected components are being computed. For the work of this paper
we take $W_0$ to be the usual $9$-neighbourhood (including the point $0$).

For $S \subset X$ define the operator $M : S \times P^2(S) \rightarrow P^2(S)$ by
\begin{equation}
M(x,\Lambda) = {M_1(x,\Lambda)} \cup M_2(x,\Lambda),
\end{equation}
where
\begin{equation}
M_1(x,\Lambda) = \cup\{\lambda\in\Lambda : \lambda \cap S_0(x) \neq\emptyset\},
\end{equation}
\begin{equation}
M_2(x,\Lambda) = \{\lambda\in\Lambda : \lambda\cap S_0(x) = \emptyset\}.
\end{equation}

It is straightforward to show that the operator $M$ has the following properties: \newline
P1: If $x \in S$ and $\Lambda$ is a partition of $S$ then $M(x,\Lambda)$ is a partition of $S$ which is coarser than $\Lambda$. \newline
P2: If $x \in S$ and $\Lambda$ is a collection of connected regions then $M(x,\Lambda)$ is a collection of connected
regions.

We define the hierarchical algorithm for connected component labeling as follows. \newline
Algorithm 1: \newline
Initialize $\Lambda= \{\{x\} : x \in S\}, S^{\prime} = S$ and then carry out the following procedure. \newline
While $S^{\prime}\neq\emptyset$,
\begin{enumerate}
\item Choose $x\in S^{\prime}$
\item Set $\Lambda := M(x,\Lambda), S^{\prime}:=S^{\prime}\backslash\{x\}$
\end{enumerate}

The algorithm must terminate because $|S| \leq|X|< \infty$. By Properties P1 and P2 the evolving
partition $\Lambda$ describes a tree of partitions of $S$ into connected sets.

We will show, using proof by contradiction, that after the termination of the algorithm $\Lambda = \mbox{Comp}(S)$. To this effect suppose that $\xi\in \Lambda_{\mbox{final}}$ and $\xi$ is not a connected component. Then $\exists\eta\supset\xi$
such that $\eta\neq\xi$ and $\eta\in\mbox{Comp}(S)$. Choose $x \in \xi, y \in \eta\backslash\xi$  such that $y \in S_0(x)$. Let $\Lambda$ be the evolving partition at the time when x is chosen in Step 1 of Algorithm 1. Then $S_0(x) \subset M_1(x,\Lambda)$
and so $S_0(x)$ is contained in $\zeta$ for some $\zeta\in\Lambda_{\mbox{final}}$. Since $x \in \xi$ it follows that $\zeta=\xi$ and so $S_0(x) \subset\xi$ which contradicts the fact that $y {\slas \in}\xi$.

It follows from this result that the final partition of $S$ generated by Algorithm 1 is independent
of the choices that are made in executing the algorithm.

\section{The sequential MCV image labeling algorithm}

Let $V$ be the set of values taken by pixels. Therefore an image can be considered as a map $\omega : X\rightarrow V$. For
grey-scale images $V = \{0, \ldots, d-1\}$ for some $d \geq 2$ (e.g. d = 256) while for color images
$V = \{(v_1,v_2,v_3) : 0 \leq v_1, v_2, v_3 \leq d-1\}$, for some $d \geq 2$, is the set of RGB triples. More generally
$V$ may be a set of vectors of multispectral components or feature vectors.

Define a point $x\in X$ to be a boundary point of a region $R \subset X$ if
\begin{equation}
(x + W_0) \cap R \neq \emptyset \mbox{ and } (x + W_0) \backslash R \neq\emptyset.
\end{equation}
Suppose that we have a connected window $W \subset {\bf Z}^2$ containing the origin (such as a rectangle
or disc centered at the origin), and an evaluation procedure $E : \Omega(R) \rightarrow \{0,1\}$ for all regions
$ R \subset W$ where $\Omega(R)$ is the set of all images on R ($\Omega(R) = \{\omega : R \rightarrow V\}$),
\begin{equation}
E(\omega) = \left\{\begin{array}{l}
1 \mbox{ if $\omega$ is acceptable}, \\
0 \mbox{ otherwise}
\end{array}\right.
\end{equation}
We also suppose that we have a permutation $\pi_{\mbox{pixels}}$ of the pixels in the image lattice
$X$ and also a second window $\Psi\subset{\bf Z}^2$. The simplest example of such a permutation is obtained
by carrying out raster scan on $X$, while a more useful permutation is a random permutation.

The MCV algorithm operates on a number of levels from level = 1 to level = max\_level. At
each level the pixels in $X$ are selected sequentially according to $\pi_{\mbox{pixels}}$. If a selected pixel $x$
bounds one or more regions in the evolving partition $\Pi$ then the image $\omega$ in the window $(x + W) \cap X$ is evaluated for homogeneity. If $E(\omega|_{(x + W) \cap X}) = 1$ then $\Pi$ is updated using the following
procedure. Compute the region
\begin{equation} \label{eq:merge1}
M_1(x,\Pi) = \cup\{R \cap (x +\Psi) : R \in \Pi, R \cap (x +W_0) \neq\emptyset\},
\end{equation}
and the collections $M_2(x,\Pi)$ and $M_3(x,\Pi)$ of regions defined by
\begin{eqnarray}
M_2(x,\Pi) & = & \{R \in \Pi : R \cap (x +W_0) = \emptyset\}, \label{eq:merge2} \\
M_3(x,\Pi) & = & \{R \backslash M_1(x,\Pi) : R \in \Pi, R \cap (x +W_0) \neq\emptyset\}, \label{eq:merge3}
\end{eqnarray}
and update
\begin{equation}
\Pi := \{M_1(x,\Pi)\} \cup M_2(x,\Pi) \cup M_3(x,\Pi).
\end{equation}
We have presented the merge operation defined by Eqn. \ref{eq:merge1}-\ref{eq:merge3} in a manner which is independent
of representation of partitions by image labelings. In a practical implementation of this
operation in which partitions are represented by image labelings the operation has a simple
form, which, clearly, must be invariant under change to an equivalent labeling. In such an implementation
the window $(x +\Psi) \cap X$ is scanned and the label of each pixel $y \in (x + \Psi) \cap X$ is
set to the label of $x$ if its label is in the set of labels of pixels in $(x +W_0) \cap X$. This operation is
clearly parallelizable and the speedup would be significant if the merge window $\Psi$ is large.

We consider a class of vision systems described by specifying
\begin{enumerate}
\item a sequence $W_1 \subset W_2 \subset \ldots W_{\mbox{n\_levels}} \subset {\bf Z}^2$ of evaluation windows
\item a sequence $\Psi_1 \subset \Psi_2 \subset \ldots \Psi_{\mbox{n\_levels}} \subset {\bf Z}^2$ of merge windows
\item evaluation functions $E_i : \Omega(R) \rightarrow \{0,1\}$ for all $R \subset W_i$ and $i = 1, \ldots, \mbox{n\_levels}$
\end{enumerate}
The vision system operates by the following algorithm
\begin{enumerate}
\item initialize $\Pi_1 = \{\{x\} : x \in X\}$
\item for $ i = 1$ to n\_levels \newline
\mbox{    }for $j=1$ to $mn$
\begin{enumerate}
\item if $\pi_{\mbox{pixels}}(j)$ is a boundary pixel then evaluate $\omega$ in the window $(\pi_{\mbox{pixels}}(j)+W_i)\cap X$
\item if it is homogeneous then update $\Pi$ according to the procedure described above
\end{enumerate}
\end{enumerate}

It is natural for the window sizes to increase as the region sizes increase. In order to apply
this algorithm it is necessary to have specified windows $W_0$, and $W_i$ and $\Psi_i$ for
$i = 1, \ldots, \mbox{max\_level}$, and evaluation maps $E_i$ for $i = 1, \ldots, \mbox{max\_level}$.
The algorithm is not strictly hierarchical
because regions may split as well as merge in going from one level to the next. However
it may be described as essentially hierarchical or semi-hierarchical, it is eventually strictly
hierarchical as the merge window size becomes large enough.

\section{Markov image evaluation}

We are given some window $W$ and a region $R \subset W$ ($R$ will usually be equal to $W$ but may be a
proper subset of $W$ if the point at which the window is located is sufficiently close to the edge
of the image). We want to be able to evaluate images $\omega : R \rightarrow V$. The approach taken in MCV
for image evaluation is that we assess images with respect to a Markov random field (MRF)
image model.

Let $\{G_x\}$ be a neighborhood system on $R$. Then an MRF on $R$ with respect to $\{G_x\}$
is an (ergodic) stochastic process $\{\Phi_x\}$ with state space $\Omega(R)$ such that
\begin{equation}
\mbox{P}(\Phi = \omega) > 0, \forall\omega\in\Omega(R),
\end{equation}
\begin{equation}
\mbox{P}(\Phi_x = \omega_x, | \Phi_y=\omega_y, y \neq x) = \mbox{P}(\Phi_x = \omega_x |\Phi_y=\omega_y,y\in G_x),\forall\omega\in\Omega(R).
\end{equation}
If $\{\Phi_x\}$ is an MRF then, by the Hammersley-Clifford theorem, there are potential functions
$V_C: \Omega(C) \rightarrow {\bf R}$ for all $C \in \Lambda$ where $\Lambda$ is the set of all cliques in $G = \{G_x\}$ and ${\bf R}$ denotes the set of real numbers, such that the equilibrium
distribution $\pi:\Omega(R)\rightarrow{\bf R}$ on $\Omega(R)$ (joint distribution) associated with $\{\Phi_x\}$ is given by
\begin{equation}
\pi(\omega) = \frac{1}{Z(T)}\mbox{exp}(-U(\omega)/T),
\end{equation}
where $U(\omega)$ for $\omega\in\Omega(R)$ is given by
\begin{equation}
U(\omega) = \sum_{C\in\Lambda}V_C(\omega|C),
\end{equation}
$T > 0$ is a constant and $Z(T) > 0$ is a normalizing constant given by
\begin{equation}
Z(T) = \sum_{\omega\in\Omega(R)}\mbox{exp}(-U(\omega)/T).
\end{equation}
$T$ is called the temperature, $U : \Omega(R) \rightarrow {\bf R}$ is called the energy function and $Z : (0,\infty) \rightarrow (0,\infty)$ is called the partition function.

The probability measure $\pi$ is the Boltzmann distribution associated
with the energy function $U$ and therefore a stochastic process with equilibrium distribution
$\pi$ can be obtained using the Metropolis algorithm.

An image $\omega\in\Omega(R)$ can be evaluated, or assessed, by computing $\pi(\omega)$. If $\pi(\omega)$ is high then the
image $\omega$ is likely to be produced by the MRF process while if $\pi(\omega)$ is low then the image $\omega$ is
unlikely to be produced by the MRF process. If we choose a threshold $\tau\in [0,1]$ then we can
define an evaluation map $E : \Omega(R)\rightarrow\{0,1\}$ by
\begin{equation}
E(\omega) = \left\{\begin{array}{l}
1 \mbox{ if }\pi(\omega) \geq\tau, \\
0 \mbox{ otherwise}.
\end{array}\right.
\end{equation}

It is straightforward to show that for all $\tau\geq 0$, there exists a $\rho \in {\bf R}$ such that for all $\omega\in\Omega(R),
\pi(\omega) \geq\tau\Leftrightarrow U(\omega) \leq\rho$. It is natural to take $\tau = < \pi >$, where $< \pi >$ denotes the expected value of
$\pi(\omega)$ for $\omega\in\Omega(R)$ according to the MRF $\{\Phi_x\}$. Thus image evaluation can be carried out, for
some $T > 0$, if we have specified an energy function $U : \Omega(R) \rightarrow {\bf R}$ and have determined an energy
threshold $\rho = \rho(T)$.

It is natural to use an autoregressive stochastic process for evaluating sub-images for homogeneity.
Suppose that we have weights $\theta_x : G_x \rightarrow [0,1]$ with
\begin{equation}
\sum_{y\in G_x}\theta_x(y)=1, \forall x\in R,
\end{equation}
e.g. $\theta_x(y) = |G_x|^{-1}, \forall x \in R, y \in G_x$.
Then there is associated an autoregressive stochastic process for which we can write
\begin{equation}
\omega(x) = \sum_{y\in G_x}\theta_x(y)\omega(y) + \epsilon(x),
\end{equation}
where $\epsilon(x)$ is a stochastic error term. If $V$ is a set of vectors, $V \subset {\bf R}^b$ (where b is the number of
bands) , then an energy function $U : \Omega(R) \rightarrow {\bf R}$ associated with such an autoregressive process is
\begin{equation}
U(\omega) = \sum_{x\in R}d(\omega(x), \sum_{y\in G_x}\theta_x(y)\omega(y))^2,
\end{equation}
where $d : {\bf R}^b \times {\bf R}^b \rightarrow [0,\infty)$ is a metric on ${\bf R}^b$ such as
\begin{equation}
d(u,v) = \sum_{i=1}^b((v_i - u_i)^2)^{\frac{1}{2}}.
\end{equation}
$U$ defines an energy function in the sense defined above with respect to the neighbourhood
system $G^{(2)}$ defined by
\begin{equation}
(\forall x, y \in R) ((x,y) \in G^{(2)} \Leftrightarrow (\exists z \in R) ((x, z) \in G, (z, y) \in G)).
\end{equation}

The equilibrium distribution can be written as
\begin{equation}
\pi(\omega) = \frac{1}{Z(T)}\sum_{x\in R}\mbox{exp}(- d(w(x),\sum_{y\in G_x}\theta_x(y)\omega(y))^2/T).
\end{equation}
This is Gaussian in the vector of deviations from the weighted sum of neighboring values.
Therefore the MRF associated with $U$ is called an autoregressive Gaussian Markov random
field (GMRF).

Suppose that $G$ is a neighborhood system on ${\bf Z}^2$. Then a sequence $\{W_i\}$ of windows can be
defined in a natural way by $W_i = G^{(i)}$ where $G^{(i)}$ are the neighborhood systems for ${\bf Z}^2$ defined
recursively by
\begin{equation}
G^{(1)} = G(x,y) \in G^{(i+1)} \Leftrightarrow (\exists z) ((x, z) \in G, (z, y) \in G^{(i)}).
\end{equation}
In other words the $G^{(i)}$ are obtained by successive dilations with respect to the structuring
element $G$ starting from $W_1 = G$. This sequence of windows can be placed to form a multiresolution image
pyramid. An image $\omega_{i+1} : W_{i+1} \rightarrow V$ can be viewed at a lower resolution on $W_i$ as the
image $\omega_i : W_i \rightarrow V$ defined by
\begin{equation}
\omega_i(x) = \sum_{y\in G_x}\theta_x(y)\omega_{i+1}(y).
\end{equation}

An approach to evaluating an image $\omega_i : W_i \rightarrow V$ is to lower the resolution by $i-1$ steps to obtain
an image $\omega_1 : W_1 \rightarrow V$ and then to evaluate $\omega_1$ using Markov image evaluation. This form
of image evaluation can be implemented as a feed-forward neural network by constructing a
pyramidal neural network with connections from nodes $y \in G_x$ in $W_{i+1}$ to $x$ in $W_i$ and giving
each such connection a weight $\theta_x(y)$. Two more layers and a threshold unit can be used to effect
the image evaluation of the lowest resolution image.

The output of the MCV system is a multiresolution sequence of partitions. After being processed
to determine additional structures such as feature vectors and classifications for the regions
in the partition sequence structure it may be passed to high level vision systems.

\section{Some results of testing the MCV algorithm}

For the experiments presented below the window $\Psi_i$ was taken to be a square of side length
$2r_i + 1$ where $r_i = 2^i$ pixels for $i = 1, \ldots, \mbox{max\_level}$. A random permutation of the pixels in the
image lattice can be computed offline and read from a file by the algorithm if it is to operate
on images of known fixed size, otherwise raster scan can be used. The algorithm was found to
be more efficient when a random permutation was used. Typically a good segmentation is
achieved using max\_levels = 9 with a random permutation as opposed to requiring
max\_levels = 11  if raster scan is used.

The image presented in Fig. 2 is the result of segmenting the image shown in Fig. 1 using the
MCV algorithm. The 27 largest ``blobs" found are shown. The different objects identified are
shown in different colors. It can be seen that the road and the sky are clearly identified. The
large tree on the left hand side of the image is also identified, however its shadow is included
as part of the identified object. The larger of the trees on the right hand side of the image is
clearly identified and parts of the other trees on the right hand side are also identified. Another segmentation 
result is shown in Figs. 3 and 4.

The MCV algorithm results in a sequence of partitions each of which can be considered as a
collection of superpixels [12].

As mentioned above it has been found experimentally that the results of the segmentation
are better when $\pi_{\mbox{pixels}}$ is random. This means that, in principle, the MCV algorithm is stochastic.
Different segmentations result when different random permutation of pixels are used. It
has been found experimentally that the differences are quite small, the Rand index [13] of
pairs of segmentations obtained using different random pixel permutations is small. Further
work may involve formal investigation of this property from a theoretical point of view.
Additionally, future work may involve incorporation of further concepts from the concurrent
vision approach into an integrated vision system such as using information such as the
NDVI (normalized difference vegetation index) and other features to inform region merging
at different levels in a system for the interpretation of remotely sensed images for the detection
of trees e.g. see [14].

\begin{figure}
\centering
\includegraphics[width=15cm]{Fig1.png}
\caption{Image from Google street view} \label{fig:Fig1}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=15cm]{Fig2.png}
\caption{MCV segmentation of image of Fig. 1} \label{fig:Fig2}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=15cm]{Fig3.png}
\caption{Google earth image} \label{fig:Fig3}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=15cm]{Fig4.png}
\caption{MCV segmentation of image from Fig. 3} \label{fig:Fig4}
\end{figure}

\section{Conclusion}

The (sequential) MCV image labeling algorithm has been described. It is a \newline  (semi-) hierarchical
algorithm which may generate a simple segmentation partition or a multiresolution sequence
of partitions. It utilizes an MRF image model in order to evaluate sub-images for homogeneity.
In the case of a Gaussian MRF this can be effected by a hardwired feed-forward neural
network. The algorithm executes very rapidly on the Berkely segmentation benchmark dataset
images and the merge operation of the algorithm is massively parallelizable. The algorithm generalizes to nD signals such as 1D (e.g. speech) or 3D (e.g. video). The MCV algorithm as we have described is fully unsupervised. However it is expected that more effective scene understanding systems will form if the algorithm is generalized to a supervised algorithm in future work. Such a generalization may involve more sophisticated merge acceptance functions involving updating of confidence levels using Bayesian methodology.

\section*{Acknowledgements}

The work described in this paper was partially funded by the Commonwealth Scientific and Industrial Research Organisation (CSIRO, Australia). Also the author would like to thank Chiang Liu, Steve Pahos, Vic Ciesieslski, Mike Rahilly, Felix Lipkin, Lachlan McAlpine, Brad Lane and Geoff Bryan for help with this work.

\section*{References}

\rf[1] Mashford, J.S. ``A method for the development of parallel concurrent machine vision systems",
Proc. ICCIMA'98 (International Conference on Computational Intelligence and Multimedia
Applications 1998), World Scientific, pp. 378-383, Feb 1998.

\rf[2] Mashford, J., Dai, W., Drogemuller, R. and Marksj\"{o}, B., ``Image classifier and scene understanding
systems of multi-agent teams", Proc. 2000 IEEE International Conference on Systems,
Man and Cybernetics, Nashville, Tennessee, USA, pp. 1460-1465, Oct 2000.

\rf[3] Mashford, J.S., ``A neural Markovian concurrent vision system for object identification and
tracking", Proc. of the 2004 International Conference on Computational Intelligence for Modelling,
Control and Automation, Gold Coast, Australia, 2004.

\rf[4] Li, S. Z., ``Markov Random Field modelling in image analysis", Springer, London, 2001.

\rf[5] Zhang, Y., Hartley, R., Mashford, J. and Burn, S., ``Superpixels via Pseudo-Boolean Optimization",
 Proc. IEEE International Conference on Computer Vision, Barcelona, Spain, 1387-1394, Nov 2011.

\rf[6] Dawoud, A. and Netchaev, A., ``Preserving objects in Markov Random Fields region growing
image segmentation", Pattern Analysis and Applications 15, 155-161, 2012.

\rf[7] Alpert, S., Galun, M., Brandt, A. and Basri, R., ``Image segmentation by probabilistic bottom-
up aggregation and cue integration", IEEE Transactions on Pattern Analysis and Machine
Intelligence 34(2), 315-327, Feb 2012.

\rf[8] Sharon, E., Galun, M. Sharon, D., Basri, R. and Brandt, A., ``Hierarchy and adaptivity in
segmenting visual scenes", Nature 442, 810-813, Aug 2006.

\rf[9] Cao, L. and Li, F.-F., ``Spatially coherent latent topic model for concurrent segmentation
and classification of objects and scenes", Proc. IEEE International Conference on Computer
Vision, Rio de Janeiro, Brazil, 1080-1087, 2007.

\rf[10] Kokkinos, I. and Maragos, P., ``Synergy between object recognition and image segmentation
using the expectation-maximization algorithm", IEEE Transactions on Pattern Analysis
and Machine Intelligence 31(8), 1486-1501, Aug 2009.

\rf[11] Mashford, J., ``Image segmentation using the MCV image labeling algorithm", Proc. of
the International Conference on Image Processing, Computer Vision and Pattern Recognition,
Las Vegas, 2013.

\rf[12] Achanta, R., Shaji, A., Smith, K., Lucchi, A., Fua, P. and S\"{u}sstruck, S., ``SLIC superpixels
compared to state-of-the-art superpixel methods", IEEE Transactions on Pattern Analysis and
Machine Intelligence 34(11), 2012.

\rf[13] Unnikrishnan, R., Pantofaru, C. and Herbert, M., ``Toward objective evaluation of image
segmentation algorithms", IEEE Transactions on Pattern Analysis and Machine Intelligence
29(6), 2007.

\rf[14] Mashford, J., Lipkin, F., Olie, C., Cuchennec, M. and Song, Y., ``Automatic Interpretation of Remotely
Sensed Images for Urban Form Assessment",  International Conference Image
Analysis and Recognition, Springer, 441-449, Oct. 2014.

\end{document}


