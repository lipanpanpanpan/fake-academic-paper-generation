\documentclass[format=acmsmall, review=false, screen=true]{acmart}

\usepackage{booktabs} % For formal tables

\usepackage[ruled,linesnumbered]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}


\acmJournal{TIST} \acmYear{0} \acmVolume{0} \acmNumber{0} \acmArticle{0} \acmMonth{0} \acmPrice{0}
\copyrightyear{2018}

\setcopyright{acmcopyright}


\received{n/a}
\received[revised]{n/a}
\received[accepted]{n/a}


\usepackage{paralist}

\newcommand{\name}{{DeepTracker}\xspace}
\newcommand{\ea}{{$\mathrm{E}_a$}\xspace}
\newcommand{\eb}{{$\mathrm{E}_b$}\xspace}
\newcommand{\ec}{{$\mathrm{E}_c$}\xspace}

\newcommand{\ti}{\textcolor[rgb]{0,0,0}}
\newcommand{\tii}{\textcolor[rgb]{0,0,0}}
\newcommand{\dy}{\textcolor[rgb]{0,0,0}}
\newcommand{\td}{\textcolor[rgb]{0,0,0}}

\makeatletter
\newcommand\footnoteref[1]{\protected@xdef\@thefnmark{\ref{#1}}\@footnotemark}
\makeatother

\begin{document}
	\title{\name: Visualizing the Training Process of Convolutional Neural Networks}
	\author{Dongyu Liu}
	\affiliation{%
		\institution{Hong Kong University of Science and Technology}
		\streetaddress{Clear Water Bay}
		\city{Hong Kong}
		\country{China}}
	\author{Weiwei Cui}
	\affiliation{%
		\institution{Microsoft Research Asia}
	}
	\author{Kai Jin}
	\affiliation{%
		\institution{Microsoft Research Asia}
	}
	\author{Yuxiao Guo}
	\affiliation{%
		\institution{Microsoft Research Asia}
	}
	\author{Huamin Qu}
	\affiliation{%
		\institution{Hong Kong University of Science and Technology}
	}

Deep convolutional neural networks (CNNs) have achieved remarkable success in various fields.
However, training an excellent CNN is practically a trial-and-error process that consumes a tremendous amount of time and computer resources.
To accelerate the training process and reduce the number of trials, experts need to understand what has occurred in the training process and why the resulting CNN behaves as such.
However, current popular training platforms, such as TensorFlow, only provide very little and general information, such as training/validation errors, which is far from enough to serve this purpose.
To bridge this gap and help domain experts with their training tasks in a practical environment, we propose a visual analytics system, \name, to facilitate the exploration of the rich dynamics of CNN training processes and to identify the unusual patterns that are hidden behind the huge amount of training log.
Specifically, we combine a hierarchical index mechanism and a set of hierarchical small multiples to help experts explore the entire training log from different levels of detail. We also introduce a novel cube-style visualization to reveal the complex correlations among multiple types of heterogeneous training data including neuron weights, validation images, and training iterations.
Three case studies are conducted to demonstrate how \name provides its users with valuable knowledge in an industry-level CNN training process, namely in our case, training ResNet-50 on the ImageNet dataset. We show that our method can be easily applied to other state-of-the-art "very deep" CNN models.
\end{abstract}


\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10003120.10003145</concept_id>
	<concept_desc>Human-centered computing~Visualization</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10003120.10003145.10003147</concept_id>
	<concept_desc>Human-centered computing~Visualization application domains</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10003120.10003145.10003147.10010365</concept_id>
	<concept_desc>Human-centered computing~Visual analytics</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10003120</concept_id>
	<concept_desc>Human-centered computing</concept_desc>
	<concept_significance>300</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Visualization}
\ccsdesc[500]{Human-centered computing~Visualization application domains}
\ccsdesc[500]{Human-centered computing~Visual analytics}
\ccsdesc[300]{Human-centered computing~}



\keywords{deep learning, training process, multiple time series,
	visual analytics, correlation analysis}





\maketitle



Deep convolutional neural networks (CNNs) have achieved huge success in solving problems related to computer vision, such as image classification~\cite{krizhevsky2012imagenet, simonyan2014very}, object detection~\cite{girshick2014rich}, semantic segmentation~\cite{long2015fully}.
However, in practice, training a high-quality CNN is often a complicated, confusing, and tedious trial-and-error procedure~\cite{bengio2012practical}.
For a large CNN, one complete training trial may take a couple of weeks.
However, domain experts often have to repeat this process several times with slightly different settings to obtain a satisfying network, which may take several weeks or even months.
To accelerate this process, experts have to understand the training processes further to check whether they are on the right track, find latent mistakes, and make proper adjustments in the next trial.
Visualizing the concealed rich training dynamics (e.g., the changes of loss/accuracy and weights/gradients/activations over time) is of vital importance to the understanding of CNN training process.
Unfortunately, CNNs usually contain a large number of interacting and non-linear parts~\cite{bengio2013representation} and recently become wider and deeper~\cite{simonyan2014very, szegedy2015going, he2016deep, szegedy2016inception}. Both of these bring considerable difficulties for experts in reasoning about CNN training behaviors.
}%Most of the current training platforms only provide experts with high-level statistical information regarding the training process, such as training/validation errors.%Although such information may be enough to determine whether the resulting network is well trained, it also conceals the rich dynamics of the internal changes in the network.%In the early age of CNNs when network structures were small and simple, this concealment was not considered a severe issue since experts could easily make inferences based on their experiences.%However, after CNNs recently became much more complex and deep~\cite{simonyan2014very, szegedy2015going, he2016deep, szegedy2016inception}, experts have begun to face considerable difficulties in reasoning about CNN training behaviors, thereby requiring the development of a tool that can reveal additional details about CNN training processes.%The rich dynamics of the internal changes in the network are concealed.%As CNNs recently become much more complex and deep~\cite{simonyan2014very, szegedy2015going, he2016deep, szegedy2016inception}, such concealment begins to bring considerable difficulties for experts in reasoning about CNN training behaviors. %\ti{However, as CNNs recently become larger and larger~\cite{simonyan2014very, szegedy2015going, he2016deep, szegedy2016inception}, such concealment begins to bring considerable difficulties for experts in reasoning about CNN training behaviors and figuring out optimization directions.}%thus causing a huge difficulty for experts to intuitively and quantitatively understand how a CNN is trained.%Thus, it is in a very urgent to develop an informative and intuitive visual analytics system to reveal more details about the CNN training process.%\ww{citation needed, only provide, then so what? the logic is not finished here.}%\ww{is cnn or dnn? is cnn blackbox or training process is blackbox}%\ww{exactly, need to explain why need to understand this beforehand, check previous comments}%\ww{The first several sentences are good, the rest are weird, basically.}\ti{
Many previous studies investigate what features have been learned by a CNN in one (e.g., usually the last one) or several representative snapshots during the training process~\cite{erhan2009visualizing, zeiler2014visualizing, springenberg2014striving, dosovitskiy2015inverting, mahendran2015understanding, zeng2017cnncomparator, liu2017towards, rauber2017visualizing, alsallakh2018convolutional, Pezzotti2018DeepEyes, kahng2018activis}.
However, little research focuses on visualizing the overall training dynamics.
One recent work~\cite{liu2018analyzing} visualizes the training process of deep neural networks, but it is not tailored for CNNs and not scalable enough to analyze the CNNs that are not only wide but also deep.}\ti{Besides, tools like TensorBoard, Nvidia Digits, and Deeplearning4j\footnote{TensorBoard: \url{https://www.tensorflow.org/get_started/summaries_and_tensorboard}; Nvidia Digits: \url{https://developer.nvidia.com/digits}; Deeplearning4j: \url{https://deeplearning4j.org/visualization}} are able to show some high-level training dynamics, such as loss and the mean of weights in a layer. However, these tools can neither handle industry-level training (i.e., training a large CNN on a very large dataset) nor answer complex questions.
For example, how the model's performance on each class of images changes over time? How the changes of parameters impact the classification results for each class? Given so many layers or image classes, which of them are worth paying more attention to and what is the best manner to support comparative analysis?
}\ti{With these concerns, we are in urgent need of a scalable visualization solution to conducting more advanced analytical tasks.}%Many studies have been conducted to help experts investigate what features have been learned by a specific CNN~\cite{erhan2009visualizing, zeiler2014visualizing, springenberg2014striving, dosovitskiy2015inverting, mahendran2015understanding, zeng2017cnncomparator, liu2017towards, rauber2017visualizing, alsallakh2018convolutional, liu2018analyzing, Pezzotti2018DeepEyes, kahng2018activis} and how a CNN processes input images~\cite{wongsuphasawat2018visualizing}.%However, these techniques are not tailored for analyzing CNN training processes.%.\ww{again, to say this, you need to make it very clear in the first para, that the training is important. but this version looks like you are talking about cnn is hard in general}%Moreover, there is little work that focuses on visualizing network training processes. %\ww{evolution is ambigious, either you make it clear at the begining, or use taining instead.}%Some existing online tools, such as Playground\footnote{\url{http://playground.tensorflow.org}} and ConvNetJS\footnote{\url{http://cs.stanford.edu/people/karpathy/convnetjs/}}, are more like tutorial tools for learning the basic ideas of neural networks. They are not designed to be used in practice.%In terms of the capability of characterizing training processes, other tools, such as TensorBoard\footnote{\url{https://www.tensorflow.org/get_started/summaries_and_tensorboard}}, Nvidia Digits\footnote{\url{https://developer.nvidia.com/digits}}, and Deeplearning4j\footnote{\url{https://deeplearning4j.org/visualization}}, only use simple charts (e.g., line charts and histogram charts) to show basic statistical information about network training.%Some online tools, such as Playground and ConvNetJS\footnote{Playground: \url{http://playground.tensorflow.org}; ConvNetJS: \url{http://cs.stanford.edu/people/karpathy/convnetjs/}}, are more like tutorial tools for learning the basic concepts of neural networks.%However, little research focuses on visualizing network training processes. Existing work~\cite{liu2018analyzing, chung2016revacnn} is neither designed for CNN training nor supporting industry-level training.%Some training platforms (e.g., TensorBoard, Nvidia Digits, and Deeplearning4j\footnote{TensorBoard: \url{https://www.tensorflow.org/get_started/summaries_and_tensorboard}; Nvidia Digits: \url{https://developer.nvidia.com/digits}; Deeplearning4j: \url{https://deeplearning4j.org/visualization}}), in terms of the capability of characterizing CNN training process, only provide simple charts to show basic statistical information over training.%These tools may perform well in the past, but they are considered inadequate nowadays as CNNs increase both in size and depth.%For example, facing dozens or hundreds of layers, experts are dazed to select a proper layer to watch. They are in desperate need for a better manner to show the information from different levels of detail. %Experts may also desire to compare the statistical information among multiple layers to more effectively diagnose the network structures and settings (e.g., hyper-parameters, initialization methods, and gradient update approaches).%Unfortunately, previous tools cannot meet these demands well.%Furthermore, there is still much useful information hidden inside CNNs, which may help experts reason about and improve CNN performances.%For instance, during a CNN training process, experts can be intrigued by a mass of questions, such as, %how the error rates for each class evolve over the entire training process,%which image classes are easy/hard for classification,%how the changes in network parameters relate to the model's performance on each class.%does a specified class have significant training intervals that have great impact on the model's performance on this class?%Motivated by these questions, we attempt to design a tool to enable experts to explore training logs from different levels and perspectives, assisting them in further understanding CNN training processes and accelerating the trial-and-error procedure.%For instance, when training a CNN on the ImageNet dataset~\cite{russakovsky2015imagenet}, which contains $1,000$ classes of labeled images, experts are interested in many questions: How does the performance (i.e., error rate) of each class evolve over the entire training process? Which image classes are easy/hard for classification? Does a specified class have significant training intervals that have great impact on the model's performance on this class? How do the changes in network parameters relate to the model's performance on each class?}%The experts shall strongly desire a tool that can allow them to explore the layer-related information in different levels of detail. Previous tools, however, cannot meet this demand well. %to be allow compare the evolving trend of parameters among multiple layers of a CNN. %, which consists of multiple layers of learnable parameters.%However, this task become challenging if only basic charts are used.% it is challenging for experts to carry out complicated tasks like comparing%\ww{why? what tasks? just say, they perform well when graph is small, but the trend is bigger and deeper, so they become more ambigious or hard to interpret}%\ww{need examples here, what kind of information?. we need to give a scope of what exact problems that we are targeting at this problem. saying something like this. In a typical imagenet training, there are 1000 valication classes, do they have similar performances (i.e., error rates)? Or there are good and bad images in them. There are usually over 1M iterations, are they equally important? Or they are particular iterations that significant changes are made to the network, and what are those changes? How those changes affect the errors and loses? etc. The purpose here is to set the expection of the reader, and raise questions to intrigue them. VERY IMPORTANT}%Thus, it is in an very urgent need to develop a tool, which can show network training information from different perspective and levels of details, to inform the experts whether a CNN evolves on a right track and guide them right directions to modify the network in time. % when some mistakes occurs.

To this end, we have to deal with two major challenges.
First, the system needs to handle the large-scale training log data.
Typically, millions of CNN parameters and tens of thousands of validation images are involved in a training process.
In addition, the training is an iteration-based process that usually requires a million iterations to complete, which makes things worse, because the parameters and classification results need to be recorded for every few iterations.
In our experiments (Sec.~\ref{sec:dataprocessing}), a sampled training log may easily exceed a couple of terabytes per training.
To allow an interactive exploration of the data at such scale, it requires not only an effective data storage and index mechanism but also a scalable visualization technique.
Second, the log information is heterogeneous.
The full log contains structure (e.g., neural network), numeric (e.g., neuron weights), image (e.g., validation dataset), and nominal data (e.g., classification results).
Given that significant insights are often hidden underneath the complex relationships among these data, our system also needs to present all these types of data intuitively and assist experts in their analysis tasks.

To address these challenges, we use a downsampling method to store the raw data, and then preprocess and organize these data in a hierarchical manner.
We also design several efficient index mechanisms to support real-time interactions.
To help experts identify the iterations of interest quickly, we propose an application-specific anomaly detection method.
\ti{We also integrate many filtering and aggregation approaches to reduce the amount of presenting information and ensure preserving the noteworthy information.}
For visualization, we design a set of hierarchical small multiples that is combined with a network structure layout to facilitate an effective exploration of the entire training log from different levels of detail.
To reveal the complex correlations among neuron weights, validation images, and training iterations, we further introduce a cube-style visualization.
The cube integrates the small multiples and a matrix-based correlation view, thereby allowing experts to effectively slice and dice the data from different perspectives.

The main contributions of this paper are summarized as follows:
\begin{compactitem}
	\item A systematic characterization of the problem of visualizing the rich dynamics in CNN training processes, and a thorough discussion and summary of the design requirements and space.
	\item A visual analytics system that integrates a tailored large data storage and index mechanism, an anomaly iteration detection algorithm, and a set of well-designed visualization techniques.
	\item A couple of new visualization and interaction techniques including hierarchical small multiples, grid-based correlation view, and cube-style visualization.
\end{compactitem}%The rest of this paper is structured as follows. We start with a literature review in Section~\ref{sec:relatedwork}. Then we characterize the problems and analyze requirements of system~\ref{sec:background}. Section~\ref{sec:model} sheds light on the data preprocessing and optimization model description, followed by the overview of our system in Section~\ref{sec:system}. Subsequently in Section~\ref{sec:evaluation}, we presents two case studies using a real dataset, expert interviews, and a user study. After that, we have a discussion of our work and finally we end with a conclusion.% % We aim to//This paper reports on//This paper provides results//This paper extends the method//This paper focus onThe purpose of this paper is toFurthermore, Moreover, In addition, we will also discuss%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Background}\label{sec:background}%In this section, we briefly introduce the basic concepts which may be referred to in the subsequent discussion of CNNs.%\vspace{-2mm}\begin{figure}[htb]
	\centering
	\includegraphics[width=0.8\columnwidth]{resources/cnn}
	\vspace{-4mm}
	\caption{Illustration of a CNN architecture that contains three types of layers (i.e., CONV layer, POOL layer, and FC layer) and transforms an image volume into a class score vector.}
	\label{fig:cnn}
	\vspace{0mm}
\end{figure}%CNNs are a special type of artificial neural networks that have been proven very effective in tasks like object detection~\cite{girshick2014rich} and image classification~\cite{krizhevsky2012imagenet}.
A typical CNN can be viewed as a sequence of layers (Fig.~\ref{fig:cnn}) that transforms an image volume (e.g., a $224\times224$ image with three color channels of R, G, and B) into an output volume (e.g., a vector of size $1,000$ indicating the probability for an input image to belong to $1,000$ predefined classes)~\cite{lecun2015deep}. There are three main types of layers to build a CNN architecture, namely, \textit{convolutional layer} (CONV layer), \textit{pooling layer} (POOL layer), and \textit{fully-connected layer} (FC layer).

A CONV layer comprises numerous neurons that are connected to a local region in the previous layer's output volume through weighted edges, many of which share the same weights through a parameter sharing scheme.
The weights in each neuron compose a \textit{filter}, the basic unit for detecting  \textit{visual features} in the input image, such as a blotch of color or the shape of an area.
The output of each neuron is computed via a dot product operation between the weights and inputs from the previous layer, and is then optionally applied via an elementwise activation function (e.g., ReLU, $max(0, x)$).
A POOL layer is usually inserted between successive CONV layers to reduce the volume of input through a downsampling operation, thereby reducing the amount of parameters and computation in the network.
The only difference between FC layer and CONV layer is that, in contrast to the neurons in CONV layer that are locally connected and have shared parameters, the neurons in FC layers have full connections to the previous layer's output volume. In addition, the output of the last FC layer is fed to a classifier (e.g., Softmax), computing the scores for all predefined classes, where each score represents the probability that an input image belongs to the corresponding class.


To obtain an effective CNN, the weight parameters in the CONV and FC layers need to be trained using gradient descent methods~\cite{bottou1991stochastic} to ensure the consistency between the predicted class labels and the predefined class for each training image.
Specifically, a training process involves two separate datasets, namely, the training set $\mathit{D_t}$ and the validation set $\mathit{D_v}$.
To start the training, the parameters of weighted layers are usually initialized via Gaussian distribution~\cite{glorot2010understanding}, and $\mathit{D_t}$ is partitioned into non-overlapping batches.
For each iteration, one batch of images in $\mathit{D_t}$ is fed to the network.
Afterward, the output classification results are compared with the ground truth (i.e., the known labels of the fed images) to compute the \textit{gradients} with respect to all neurons.
These gradients are then used to update the weights of each neuron.
When all batches in $\mathit{D_t}$ are completed (i.e., finish one \textit{epoch}), $D_t$ is reshuffled and partitioned into new non-overlapping batches.
After several epoches, the initially-randomized neural network will be gradually shaped into a specified network targeting at a specific task.
Meanwhile, for every given number of iterations, the network is evaluated via $\mathit{D_v}$.
Similarly, $D_v$ is fed into the network and then the output classification results are collected and compared with the ground truth.
However, the results are only used to validate whether a training process goes well and never used to update neuron weights.
CNNs have recently received considerable attention in the field of visualization~\cite{seifert2017visualizations}.
Existing approaches can be classified into two categories, namely, feature-oriented and evolution-oriented.

Feature-oriented approaches aim to visualize and interpret how a specific CNN behaves on the input images to disclose what features it has learned.
Most of the existing studies belong to this category.
Some studies~\cite{zeiler2011adaptive,zeiler2014visualizing} modify part of the input and measure the resulting variation in the output or intermediate hidden layers of a CNN.
By visualizing the resulting variations (e.g., using a heatmap), users can identify which parts of the input image contributes the most to the classification results.
By contrast, other studies~\cite{zeiler2014visualizing,springenberg2014striving,mahendran2015understanding,dosovitskiy2015inverting} attempt to synthesize an image that is most relevant to the activation (i.e., the output of a layer after an activation function) of interest to help experts determine which features of a specified image are important for the relevant neurons.
For example, Mahendran and Vedaldi~\cite{mahendran2015understanding} reconstruct the input images that can either activate the neurons of interest or produce the same activations as another input image.
Besides, some methods focus on retrieving a set of images that can maximally activate a specific neuron~\cite{girshick2014rich,erhan2009visualizing}.
In this manner, users can discover which types of features or images are captured by a specific neuron.
Built on this method, Liu et al.~\cite{liu2017towards} develop a visual analytics system that integrates a set of visualizations to explore the features learned by neurons and reveal the relationships among them.
In addition, some work~\cite{rauber2017visualizing,chung2016revacnn,kahng2018activis,Pezzotti2018DeepEyes} utilizes dimension reduction technique to project the high-dimension activation vectors of FC or intermediate hidden layers onto a 2D space to facilitate revealing the relationships among outputs.

In contrast to those studies that investigate how a specified network works, only few studies concentrate on visualizing network training processes.
One typical method is to pick several snapshots of a CNN over the training process and then leverage feature-oriented approaches to compare how a CNN behaves differently on a given set of inputs at various iterations~\cite{zeiler2014visualizing, chung2016revacnn, zeng2017cnncomparator, alsallakh2018convolutional}.
For example, Zeiler and Fergus~\cite{zeiler2014visualizing} use deconvnet approach to visualize a series of synthesized images that are most relevant to one activation of interest at a few manually picked snapshots, and then observe the differences between them.
\ti{
Zeng et al.~\cite{zeng2017cnncomparator} present a matrix visualization to show the weight differences of filters of one layer as well as this layer's input and output in two model snapshots. Their system also supports side by side comparison on the learned features of neurons (the computation method is similar to the work~\cite{girshick2014rich}) in different model snapshots.
One limitation of these methods is that when there are myriad filters, images, and iterations, it is challenging to select proper ones to observe and compare.
By contrast, we attempt to reveal the rich dynamics of the network parameters and the classification results at a larger scale to help experts find the notable filters, images, and iterations.
In this point, Alsallakh et al.~\cite{alsallakh2018convolutional} analyze the same data facets (i.e., input images, network parameters, and classification results). However, the work focuses more on identifying the hierarchical similarity structures between classes and still belongs to the category of multiple snapshots comparison, thereby suffering from the same limitation.
}

To analyze the evolution of CNN parameters, Eliana~\cite{eliana2016pca} treats the parameters of the entire network at one iteration as a high-dimension vector, uses PCA to map the vectors at all iterations onto a 3D space, and creates trajectories for these points. However, this visualization is too abstract to extract useful insights for understanding and debugging the training process.
To analyze the classification results, Rauber et al.~\cite{rauber2017visualizing} create a 2D trails graph to present an overview of how the CNN classification results evolve by leveraging the projection techniques.
However, this method suffers from scalability and visual clutter problems when applied to large-scale datasets (e.g., ImageNet). Besides, this method only provides a very high-level overview and cannot answer those questions that involve individual classes or images.
\ti{The work most similar to ours should be the one by Liu et al.~\cite{liu2018analyzing}, whereas the work mainly targets at deep generative models and would have serious scalability issue if applied in an industry-level CNN training. Besides, compared with that work, we specifically provide a series of hierarchical methods that are tailored for CNNs to visualize the training dynamics, including classification results and network parameters.
}%We also attempt to discover the correlation between network parameters and validation image classification results at multiple scales.%. Specifically, we propose a hierarchical small multiples visualization combined with a network graph to support the exploration of network parameters over training at multiple scales.%In particular, we propose a highly space-efficient heatmap-based small multiple visualization to facilitate the exploration of classification results over training at different levels of detail.%In details, We also present a novel correlation matrix and cube-style visualization to help experts explore the complex relationships among network parameters, classification results, and iterations, thereby allowing them to quickly identify the notable filters, images, and iterations.\ti{Furthermore, we design a novel correlation matrix and 2.5D cube-style visualization to help experts examine the complex relationships exist among network parameters, classification results, and iterations.}%\ww{this paragraph is too short, need to say more about the difference between ours and theirs.}%With a different purpose, our work focuses on analyzing how the network parameters themselves and the classification results of all validation images change.%~\ww{sentence not clear. It is really important to let reviewers know your work is different from the previous. If you say this unclear, I only know there is different, but I do not know that it is. Then I have two choices, either taking your words for it, or questioning your words, you need to explain.}%In addition, some popular online tools, such as Tensorboard~\cite{tensorboard}, Nvidia Digits~\cite{nvidiad}, and Deeplearning4j~\cite{Deeplearning4j}, only use simple charts to show high-level statistical information of network parameters over the training process and cannot reveal more detailed statistical information regarding to filter-level. Moreover, due to the trend that CNNs are becoming bigger and deeper~\cite{he2016deep,szegedy2016inception,szegedy2015going,simonyan2014very}, these tools are not fitted to execute more complicated exploratory tasks such as comparing the trends of one type of statistical information among multiple layers.%\ww{what is desired patterns? Better say that users are no longer happy with these primitive, overly-aggregative information, and desire to know more...}%\td{To reveal more details about CNN training processes, we propose a novel tree-based small multiple time-series visualization technique which can display the evolutions of network parameters (i.e., weight and gradient) from different levels of details. Besides, we leverage pixel visualization technique to reveal the filter-level parameter evolution. Apart from the inner parameters of a CNN, we also present a heatmap-based small multiple visualization to help users gain more detailed information about the classification results for each class. More importantly, to the correlation analysis between multiple kinds of data, we novelly are the first who present a novel time-cube visualization technique to allow users to conduct co-analysis between network parameters and image labeling data.}\ww{duplicated, probably remove.}\subsection{Multiple Time Series Visualization}

Time series data have been extensively studied due to their ubiquity.
Numerous approaches~\cite{aigner2011visualization, aigner2008visual, bach2014review} to time series visualization have been proposed.
Our system also falls into this field, since training logs are essentially a type of time-based information.
Specifically, our system is most related to existing work that visualizes multiple time series.
To visualize multiple time series, one method is to place multiple charts (e.g., line charts) in the same graph space to produce overlapping curves. However, this method reduces the legibility of individual time-series~\cite{javed2010graphical}.
In contrast to overlaying multiple series, one popular alternative is to use small multiples~\cite{tufte1983visual} that split the space into individual graphs, each showing one time series. Using small multiples also allows for an effective comparison across charts. Several factors may also affect the performance of small multiples~\cite{heer2009sizing,javed2010graphical}, such as the types of charts used (e.g., line charts and horizon graphs), the number of series and the vertical space allocated to each series. The improper use of time-series charts, the increased series, and the small vertical space of each series will result in a serious visual clutter problem.

In this work, the evolution of the image classification results of each class and the weight parameters of each layer can be viewed as two types of multiple time series data. Given the large number of classes and layers in a practical CNN training, we identify several space-efficient charts that can characterize the training dynamics. Besides, we propose a similarity-based layout and a hierarchical exploration method to support the exploration of relationships among multiple time series to address the visual clutter problem. We also present a novel cube-based visualization, targeting at the exploration of complex relationships among various types of heterogeneous time-series data (e.g., image classification results, neuron weights, and training iterations).


From our regular discussions, we learned that the training process should be carefully babysat. The experts have to tune and fix a number of \textit{hyper-parameters} (learning rate, batch size, layer number, filter number per layer, weight decay, momentum, etc.) before starting a training trial.
These hyper-parameters, which strongly influence how a CNN is trained, are usually selected based on the experiences learned from their previous trials.
During a training, there are several useful quantities the experts want to monitor, such as loss function (the residual error between the prediction results and the ground truth), train/validation error rate (the percentage of mislabeled images), weight update ratio (the ratio of the update magnitudes to the value magnitudes), and weight/gradient/activation distributions per layer. Basically, both loss and error rate should decrease over time; the consistent increase or violent fluctuation of loss on $D_t$ may indicate a problem; a big gap between the error rates of $D_t$ and $D_v$ may suggest that the model is over-fitting, while the absence of any gap may indicate that the model has a limited learning capability; the update ratio\footnote{In most cases, if the update ratio is lower than 1e-3, the learning rate might be too low; if it is higher than 1e-3, the learning rate is probably too high.} is expected to be around 1e-3; the weight distributions per layer in the beginning should overall follow Gaussian distributions with different standard deviation settings\footnote{\label{note7}Xavier Initialization~\cite{glorot2010understanding} is applied in our model. Basically, the deeper (close to loss layer) the layer is, the smaller the sd is.} and may become diverse after training; and exploding or vanishing gradient values are a bad sign for the training.
However, the experts still strongly desire to examine more details underlying the statistic, so that they can gain more knowledge and suit the remedy to the case when problems occur.
For example, the experience tells the experts that it is better to continue training models (e.g., ResNet~\cite{he2016deep}) with the same learning rate for a while rather than turn it down immediately, when the overall error rate stops to decrease. The experts are very curious about what happens to the model and its performance on each class of images during the period.
Also, we may often see a fluctuation of loss or an occasional exploding gradient values, and what brings about this? Are there any layers or filters that behave abnormally?
These details are never uncovered before.
Thus, the experts strongly desire a tool to enable them to explore the hidden dynamics behind a CNN training.
After several rounds of structured interviews with the experts, we finally summarized and compiled the following list of requirements:


	\item \textbf{Exploring multiple facets of neuron weight information}.
	A single iteration may have millions of weight updates, but individual values are generally meaningless to the experts.
	Instead, the experts are more interested in the statistical information of these weights at different levels of detail (e.g., CONV layer level and filter level).
	All three experts emphasized the importance of intuitively and effectively examining general types of statistics, such as sum and variance, between these levels.
	Besides, \ea and \eb strongly desire to see the weight change degree for filters over iterations to identify which filters change dramatically at which iteration or how a filter changes across iterations.


	\item \textbf{Comparing multiple layers}.
	All three experts like to compare layer-level statistical information.
	For example, they want to know whether a specified measure of different layers show a similar trend or distribution (e.g., whether the sum is positive or negative).
	Accordingly, our visualization should also help these experts in performing such comparisons.

	\item \textbf{Tracking the classification results of validation classes}.
	Validation is a critical step in the training process that ``test drives'' the trained CNN and tracks its performance change across iterations~\cite{bengio2012practical}.
	Previous tools only measure the global validation loss/error, thereby concealing the rich dynamics of how the image labels of each class change over time.
	When the error rates do not reduce as expected, the experts find that such highly-aggregated information is useless and cannot help them understand why or when the training runs into a bottleneck.
	Therefore, the experts want to know how the images of different classes behave differently and identify those classes that are easy or difficult to train.

	\item \textbf{Detecting important iterations}.
	One complete training process usually contains millions of iterations, but it is obvious that not all iterations are equally important.
	For example, some image classes may suddenly change their error rates after certain weight updates.
	The experts are interested in these patterns, which may help reveal in-depth relationships between filters and image features.
	However, the overall error rate trend does not help much, since it generally decreases slowly and steadily.
	Thus, the experts hope that our system can help them identify the abnormal iterations and the corresponding classes.


	\item \textbf{Examining individual validation classes}.
	Our initial prototype shows that different classes clearly have different error rate evolution patterns.
	Thus, experts \eb and \ec are curious about those classes with very poor or excellent performance, thereby desiring to further explore the image label information for these classes.
	For example, they want to see whether and why some images are always misclassified.

	\item \textbf{Enabling correlation exploration}.
	Apart from analyzing the weight and validation data separately, the experts are also curious about their relational patterns.
	They are specifically interested in uncovering the relationships between the layers or filters and the validation images, such as how the changes in network parameters respond to the image labeling results for each class.
	By connecting these two pieces of information together, they hope to gain fundamental insights into the behaviors of CNNs and to improve training results.
\end{compactenum}%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{System Overview}\label{sec:systemoverview}\begin{figure}[htp]
	\centering
	\includegraphics[width=0.8\columnwidth]{resources/system_overview}
	\vspace{0mm}
	\caption{Three components of \name. The raw data are preprocessed into a hierarchical structure and then stored into five application-specific data indexes to enable real-time interactions. On top of the efficient data storage, several visualizations are combined together to help experts with analysis tasks from different levels and perspectives.}
	\label{fig:system_overview}
	\vspace{0mm}
\end{figure}\name is a web-based application developed under the full-stack framework, MEAN.ts (i.e., MongoDB, Express, AngularJs, Node, and Typescript). The back-end part of our application is deployed in a server with 3.10GHz Intel Xeon E5-2687W CPU and 32GB memory.

The architecture of our system (Fig.~\ref{fig:system_overview}) begins with the data processing part, where the entire training log is hierarchically organized, and several application-specific indexes are built to support real-time interactions.
On top of the efficient data storage, we build three coordinated views, namely, the Validation View, the Layer View, and the Correlation View, to support an interactive analysis from different levels and perspectives.
The Validation View aims at providing a visual summary of CNN performance on different validation classes.
By combining our anomaly detection algorithm and small multiples, experts can easily identify different image class behavior patterns and critical iterations for each image class (\textbf{R3}, \textbf{R4}).
Experts may also drill down to the class of interest to explore further image label information (\textbf{R5}).
The Layer View aligns the weight information with the CNN structure to help experts explore various statistical information in the network hierarchy.
Experts can further drill up or down in the network hierarchy to compare these measures at different levels of detail (\textbf{R1}, \textbf{R2}).
The Correlation View presents a novel grid-based visualization method to provide an overview of the correlation between the image classification results and the neuron weights of each filter (\textbf{R6}).
\ti{
The three views compose a cube, with which the experts can simultaneously explore the changes of class-level performances, the variations of filter-level weights, and the correlations between them.
}%After identifying several correlations of interest, the experts may further align these three views on a cube to compare these correlations in detail without frequently switching between views.%In addition, the three views can be combined into a 3D cube, with each face representing one view, thereby allowing users explore the correlations more conveniently without switching views frequently.\section{Data Acquisition and Construction}\label{sec:dataprocessing}%\dy{batch norm's parameters. There is no need to save norm, when tested, the network's norm values will be set to 0, do postbn first. As norm'values are only related to the input image volumes, useless.}%We worked closely with the experts and directly inserted source codes into their training programs to dump necessary information for analysis.	%As our focus is industry-level CNN training, we conduct our experiments with ResNet-50~\cite{he2016deep} and ImageNet Dataset~\cite{russakovsky2015imagenet}.\ti{
The primary motivation of this work is to monitor industry-level CNN training processes. Therefore, we conduct our experiments with ResNet-50~\cite{he2016deep} and ImageNet Dataset~\cite{russakovsky2015imagenet}.
ResNet-50, containing 50 weighted layers (i.e., CONV and FC layers), is among the most popular CNNs that have been recently used in practice and meanwhile ImageNet 2012 is also among the largest and most challenging publicly available datasets.
The dataset includes $1,000$ classes of images, each class containing $1,300$ training images and $50$ validation images.
Training such a model needs around 120 epoches (nearly 1.2 millions iterations when batch size is 128) to achieve convergence.
Simply dumping all the information for every iteration can easily have the size of dumped data exceed several petabytes and take about 4 weeks. Through discussion, we all thought that $1,600$ is a reasonable interval to capture meaningful changes (about 7 times per epoch). This reduces the log to a manageable size (about 1TB).
}\ti{
For each dump, we recorded two pieces of information, namely, neuron weights/gradients of CONV layer and FC layer and image classification results.
The parameters on BN layers were not recorded, as they can be totally recovered given the weights on CONV and FC layers and always need to be updated when applied in a new dataset.
Besides, we did not record the activations of each layer/filter for every validation image, as doing so is technically impracticable considering the extremely large models and datasets and the limited disk storage. Further, activation evolution visualization is beyond the research scope of this paper.
Sec.~\ref{sec:conclusion} discusses activation visualization is indeed a perfect complementary technique to our work.
}% However, Besides, as we have already dumped all the necessary weights, one can easily recover the entire network at certain dumped iteration and then generate the corresponding activations of the images of interest to conduct further analysis (see the discussion of future work in Sec.~\ref{sec:conclusion}).%Although some CNNs, such as ResNet, contain batch normalization layer (BN layer), the experts think it is unnecessary to record and analyze such information, because the parameters on BN layers can be recomputed given the weights on CONV and FC layers and part of the input images for current testing dataset.%In all, there are 1.3 million training images and $50,000$ validation images.%, and ImageNet 2012 is also one of the benchmark and challenging datasets%As the experts emphasize the importance of working in practical environment (i.e., train a large CNN on very large scale dataset). Thus, suggested by the experts, we mainly trained resnet-50~\cite{he2016deep}, one of the default choice for using CNN in practice with 50 layers~\cite{cs231n}, on the ImageNet 2012~\cite{russakovsky2015imagenet} dataset. The dataset has 1000 classes of images, each containing $1,300$ high-resolution training images and $50$ validation images respectively. In all, there are 1.3 million training images and $50,000$ validation images.%During the experiments, we found that dumping the information at each iteration can easily increase the overall training time at least by one order of magnitude (about 3-4 weeks without dump operation when training the model on a machine with 4 TITAN X GPUs) and require several petabytes to store one complete training log, both of which are unrealistic and unnecessary in practice.%After discussing with the experts, we increased the dumping interval to $1,600$ iterations.%Since each training in our experiments requires about 1.2 million iterations (In our basic setting, the mini-batch size is 32 for one GPU and the total batch size is $32*4=128$ due to the use of four GPUs), $1,600$ is considered a reasonable interval to capture meaningful changes (about 7 times per epoch) and to reduce the log to a manageable size (around 1TB per complete training). We have carried out several times of experiments with different batch size and learning rate settings.%as the parameters of BN layers totally depends on the current weights of network.%The whole network can be safely recovered only knowing the weights of CONV and FC layers, as the parameters of BN layers can be computed with the weights on CONV and FC layers and the input images.%After discussing with the experts, we identify two fundamental yet critical pieces of information in the training process, namely, the layer-relevant weight/gradient information and image classification results for each class at every iteration. Considering the huge data scalability if all the parameters and image information are dumped for all iterations, we use downsampling on the raw data and only record information at prepicked iterations. %In our case, we record data nearly seven times per epoch (i.e., 1600 iterations when batch size is 128) and there are totally 120 epochs. Even sampling is applied, the raw data (billions of parameters) still easily exceed a couple of tera-bytes for each training. To preprocess such amount of data and organize it in a hierarchical manner to support out analytical tasks. There are two types of hierarchy structures related to layer information and image classification information, respectively.
We organized the weight/gradient information according to the natural hierarchial structure of ResNet-50. It consists of four \textit{CONV modules} (plus the first CONV layer and the final FC layer, there are 50 layers in total). Each module contains several \textit{bottleneck blocks}~\cite{he2016deep} that comprise three to four basic CONV layers (data storage in Fig.~\ref{fig:system_overview}).
Thus, we grouped all neuron weights to align with such hierarchy.
\ti{
In a similar manner, we organized the classification results hierarchically from individual level, class level, to model level.
We stored all the data into MongoDB\footnote{MongoDB is a free and open-source cross-platform document-oriented (NoSql) database. \url{www.mongodb.com}}.
In particular, we precomputed all the relevant aggregation values, such as weight means and error rates, for each filter, layer, image, and class.
Nevertheless, the distilled data still remain too large to load into memories (about dozens of gigabytes per training).
Therefore, we analyzed the frequent needs of the experts and built several indexes to enable real-time interactions, including Layer-Stat index $I_{ls}$, Layer-Filter index $I_{lf}$, Iter-Filter index $I_{if}$, Cls-Stat index $I_{cs}$, and Cls-Image index $I_{ci}$.
\begin{compactitem}
	\item $I_{ls}$ retrieves the statistic values (e.g., mean and sd) at every iterations for any given layer;
	\item $I_{lf}$ lists all the filter-level information (e.g., changing degree of each filter) at every iterations for any given layer;
	\item $I_{if}$ searches the top changing filters from all layers at any given iteration;
	\item $I_{cs}$ extracts class-level information (e.g., class performances, the different types of abnormal images~Sec.~\ref{sec:anomaly}) over all iterations for any given class;
	\item $I_{ci}$ fetches the meta-data of images for any given classes.
\end{compactitem}
}%\textbf{Layer-Stat Index $I_{ls}$}. The weights on a layer can be seen as a vector $\theta$, which can be summarized in various ways, such as sum, sd, and mean magnitude (the average of the absolute value of each weight).%For any type of statistic, with the index $I_{ls}$, we can quickly retrieve the statistic values over all $n$ iterations of a layer $L_i$ as \{{$L_i$} $\mid$ $s_1, ..., s_n$ \}. %Notice $s_j$ is an object that stores each type of statistic of the weights of layer $L_i$ at iteration $j$. %\textbf{Layer-Filter Index $I_{lf}$}. This is the second level of index to help our system locate the filters inside a layer. The weights of each filter are treated as a vector $\beta$. %In practice, the experts are more interested in how the weights in a filter differ from the previous iteration. In this end, many vector similarity measurement can be used, such as Euclidean distance, Manhattan distance, and cosine similarity.%For each type of measurement, each entry in $I_{lf}$ lists all the distance measures of all filters in layer $L_i$ over all $n$ iterations, that is, \{{$L_i$} $\mid$ $f_{i1}, ..., f_{in}, f_{j1}, ...$ \}.%\textbf{Iter-Filter Index $I_{if}$}. Unlike $I_{lf}$, $I_{if}$ retrieves all filters in all layers at a specific iteration \{{$I_i$} $\mid$ $f_{ji}, f_{ki}, ...$ \}. This index is built to identify which filters have changed the most at the several iterations of interest.%\textbf{Cls-Stat Index $I_{cs}$}. Similar to layer-stat index $I_{ls}$, each entry $I_{cs}[c_i]$ in this index stores all the class-relevant information of a given class over all the $n$ iterations, such as error rate and different types of abnormal image numbers (Sec.~\ref{sec:anomaly}). For a specific type of class-relevant information, one can easily obtain the value of a specified type of an image class through \{{$C_i$} $\mid$ $s_1, ..., s_n$ \}. %\textbf{Cls-Image Index $I_{ci}$}. This index allows a quick retrieval of image-relevant information, including image file name, original label, and the computed classification results (i.e., computed labels) on all $n$ iterations, by a specific class name.%For the layer information, there are several levels of details due to the natural design methodology of very deep CNNs. In our case (i.e., resnet-50), there are five big CONV layers, each includes many ``bottleneck block''~\cite{he2016deep} (another popular kind of similar structure is called ``inception block'' used in google-inception-v4~\cite{szegedy2016inception}) that consists of 3 or 4 elementary CONV layers (as mentioned in Sec.~\ref{sec:background}). Requested by the experts, we compute the statistical information of high-level layers by aggregating all the contained elementary CONV layers to allow the experts to compare the information from different aggregation levels, which is never done in prior work. Besides, for each elementary layer, the information about filters in it is also significant and is also stored. %Then, we recorded the classification result and correctness of each validation image in each dump.%Afterward, we aggregated the information for each class and over all iterations for individual images.%All raw data were preprocessed and stored into MongoDB\footnote{MongoDB is a free and open-source cross-platform document-oriented (NoSql) database. \url{www.mongodb.com}}. In particular, we precomputed all the relevant aggregation values, such as weight means and error rates, for each filter, layer, image, and class. These values were packed together based on their types and positions in the network hierarchy. %For example, all the label information regarding the images of one class were packed as a \textit{document} (the basic storage unit in MongoDB) and all these documents were further combined as a \textit{collection} (a higher level of storage unit in MongoDB). A similar method was employed to handle the network parameter information which has four levels (from the CONV module level to the filter level).%\ww{talk more about the mango storage, otherwise, it will sound trival. People may think it as simple as clicking a button in SQL.}%For the classification information, for each image at one iteration, we have an output 1000-dimension-vector, each dimension representing the probability of the image belonging to a corresponding class. The CNN chooses the one with the highest probability as the classification result. In contract to the previous tools, which only record one value indicating the overall error rate for all images in $D_v$ (model level), we further store the error rates for each class (class level) and record the labeling information over time for all images (image level). Besides, to support the real-time interactions, we build the following application-specific indexes.%\ww{when when feeding a image, we have a output of vector with length = 1000, representing 1000 classes of image, each bit represents the probability of the image belonging to that class, and the system chooses the one with the highest score as the classification result. we compare the result with its know label, if match, so it is accurate, if not, so it is wrong. then for each image, at each iteration, we have a true/false value. then we can collect a sequence of true/false representing the validation history of that particular image... for the gradient history, you need to do the same. }%\ww{maybe we only say two categories, consistent with sec 2 and easy to remember, and if needed, you can give a sentence or two in the system overview or case study, just saying, requested by the experts, we also put the common overall loss/error curves that are also commonly seen in many online visualizations like xxxx. move arguments from sec 2 here. keep sec 2 dry and objective. We explain two types of log data and argue their importance here.}%\textbf{Layer-Stat Index $I_{ls}$}. The weights on a layer can be seen as a vector $\theta$, which can be summarized in various ways, such as sum, std, mean magnitude (the average of the absolute value of each weight).%For any type of statistic, with the index $I_{ls}$, we can quickly retrieve the statistic values over all the $n$ iterations of a layer $L_i$ (\textbf{R1, R2}), namely, \{\underline{$L_i$} $\mid$ $s_1, ..., s_n$ \}. %Notice $s_j$ is an object that stores each type of statistic of the weights of layer $L_i$ at iteration $j$. %%\textbf{Layer-Filter Index $I_{lf}$}. This is the second level index to help our system locate filters inside a layer. The weights of each filter are treated as a vector $\beta$ too. %In practice, the experts are more interested in how the weights in a filter differs from the previous iteration. In this case, many vector similarity measurement can be used, such as Euclidean distance, Manhattan distance, and cosine similarity.%Thus, for each given type of measurement, each entry in $I_{lf}$ lists all distance measures of all filters in layer $L_i$ over all the $n$ iterations (\textbf{R1, R2, R6}), that is, \{\underline{$L_i$} $\mid$ $f_{i1}, ..., f_{in}, f_{j1}, ...$ \}.%%\textbf{Iter-Filter Index, $I_{if}$}. Different from the index $I_{lf}$, the iter-filter index $I_{if}$ retrieves all the filters in all layers at a given iteration \{\underline{$I_i$} $\mid$ $f_{ji}, f_{ki}, ...$ \}. This index is built to search which filters change most hugely at the several iterations of interest (\textbf{R4, R6}).%%\textbf{Cls-Stat Index, $I_{cs}$}. Similar to the layer-stat index $I_{ls}$, each entry $I_{cs}[c_i]$ in this index stores all the class-relevant information (\textbf{R3}) of a given class over all the $n$ iterations, such as error rate, different types of abnormal image numbers (\textbf{R4}, Sec.~\ref{sec:anomaly}). For a given type of class-relevant information, one can easily obtain the value of the specified type of a image class through \{\underline{$C_i$} $\mid$ $s_1, ..., s_n$ \}. %%\textbf{Cls-Image, $I_{ci}$}. This index allows quickly retrieving the image-relevant information (\textbf{R5}) including image file name, original label, and the computed classification results (i.e., computed labels) on all the $n$ iterations, by given a class name.%std (standard deviation), var (variance), distribution related information (i.e., min, one quarter, mean, three quarter, max), %mean magnitude (the average of the absolute value of the parameters), the ratio of mean magnitude.%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Visualization}\label{sec:visualization}

In this section, we describe our three coordinate views, namely, the Validation View, the Layer View, and the Correlation View, that help experts accomplish the aforementioned analytical tasks.

\subsection{Validation View}
Several urgent requirements (\textbf{R3}, \textbf{R4}, \textbf{R5}) from the experts need to examine how the evolving CNN acts differently on the validation images of each class rather than how the overall validation error rate differs over training.
Thus, we design the Validation View (Fig.~\ref{fig:case1-2}\&\ref{fig:case1}) to present all image classes in $D_v$.
	\centering
	\includegraphics[width=0.95\columnwidth]{resources/tist_cluster}
	\vspace{-2mm}
	\caption{From top (a) to bottom (b), image classes are more and more difficult to train.}
	\label{fig:case1-2}
	\vspace{-4mm}
\end{figure}\subsubsection{Visual Encoding}\label{sec:validation_view_encode}%The validation view based on a horizontal small multiples allows users to obtain a quick overview of each class performance and make comparison among them.\ti{By default, the view starts with a visualization of \textbf{cluster-level} performance (\textbf{R3}).
The classes with similar evolving trends form a cluster and then their error rates at every iteration are averaged.
The averaged error rates are then depicted as a colored stripe, where the x-axis encodes the iterations and the error rates are encoded by colors (Fig.~\ref{fig:case1-2}).
We choose k-means as the clustering algorithm and $k$ can be adjusted according to demands (Fig.~\ref{fig:case1-2} shows the case when $k=4$).
Experts can open up one cluster to further examine the performance in \textbf{class-level} (\textbf{R3}).
The design is based on the following considerations.
First, the experts are more interested in the overall classes than in individual iterations.
Thus, small multiples technique (juxtaposed techniques) is chosen for their superior performance in high-level comparison tasks (e.g., global trends for every series)~\cite{javed2010graphical}.
Second, we cannot present all the classes ($1,000$ in ImageNet) at one time, we have to consider a hierarchical and highly space-efficient visualization.
However, many traditional charts, such as line charts and horizon graphs, require a larger vertical space~\cite{heer2009sizing} than 1D heatmaps.
Compared with traditional charts, heatmaps are also more easy to do side by side comparison for their symmetrical space (i.e., no irregular white spaces).
As a result, all experts prefer the heatmap-based small multiples.}%By explaining each chart's strengths and weakness to the experts, we finally%thereby facilitating their comparison. We present the experts with some design alternatives, such as filled line charts and horizon graphs, and explain to them their relative strengths and weaknesses. All experts prefer the heatmap-based small multiples.%\textbf{Class-level performances}. By default, the Validation View presents an overview of how the performances (i.e., error rates) of validation classes evolve over training.%Each class is depicted as a colored stripe. The x-axis encodes the iterations and the error rates are encoded by colors (Fig.~\ref{fig:case1-2}) to enable experts to compare and obtain a quick overview of all performances (\textbf{R3}).%Each class has its own time series, thus small multiples~\cite{javed2010graphical} are used to show all classes, each series represented by a heatmap chart.%The heatmap can be viewed as $n$ (i.e., the number of dumped iterations) rectangles of a fixed height and one pixel width. The error rate at iteration $i$ is encoded by the color on $ith$ rectangle, where the diverging color from green to red is used with the deep red indicating a high error rate.%In addition, to help experts examine classes in groups, we utilize Multidimensional Scaling (MDS)~\cite{kruskal1964nonmetric} to ensure that classes with similar evolving patterns are placed close.%Besides, since the experts not only want to see one class performance changes over time but also desire to explore the relationships among different classes (R.3), we further utilize the vertical position channel to encode this type of information.%To this end, for a class $C_i$, its error rates at each iteration can be views as a vector [$er_1, er_2, ..., er_n$], where each bit is a real number ranging from 0 to 1.%Then, we can compute the cosine similarities among different classes and utilize Multidimensional Scaling (MDS)~\cite{kruskal1964nonmetric} to create the layout.%MDS is a well-established dimension reduction method which is good at preserve global structure than other methods. In our case, we use MDS to project all the high dimension class vectors onto a 1D value $c_i$ and then sort the vertical positions of each class according to the size of value $c_i$. In the resulting layout, thereafter, the classes of a similar performance evolution trend will stay more closer globally.%\textbf{Design Consideration}.\textbf{Image-level performances, R5}. The class-level color strips can be further unfolded to explore the image-level evolution patterns.
Unfolding a heatmap reveals a pixel chart (Fig.~\ref{fig:case1}d), with each row (1px height) representing an image and each column (1px width) representing an dumped iteration (consistent with the class heatmap).
We use red and green colors to indicate the incorrect and correct classifications, respectively.
Meanwhile, the experts can zoom/pan the pixel chart for a closer inspection. Clicking on a row shows the original corresponding image.

\textbf{Anomaly iterations, R4}. \ti{As experts are concerned about the iterations with abnormal behaviors, we particularly propose a algorithm to detect these anomaly iterations (refer to Sec.~\ref{sec:anomaly}).
Experts can choose to only show the classes with anomaly iterations (Fig.~\ref{fig:case1}).
At this point, for each class-level color stripe, we use triangular glyphs to highlight these detected anomaly iterations.
The upside-down triangles ($\bigtriangledown$) and normal triangles ($\triangle$) indicate those anomaly iterations that are detected by the left-rule and right-rule, respectively.
The widths of triangles encode the anomaly scores.
Experts can set a threshold value to filter the triangles with low anomaly scores.}\subsubsection{Anomaly Detection}\label{sec:anomaly}%have been proposed for a variety of analytical tasks, such as system diagnosis and biological engineering.  Markov is treated as a box. Considering the special application scenario, the rule-based model is more favorable.
In our scenario, the classification results for an image can be represented by a 0/1 sequence ($[a_1, ..., a_n]$), where each element represents a correct or incorrect result at the corresponding validation iteration.
The experts are curious about the iterations when a significant amount of 1/0 flips (i.e., 0 to 1 or 1 to 0) occur for a class.
In general, this problem can be modeled and solved using Markovian-based anomaly detection algorithms~\cite{aggarwal2015outlier}.
Despite the popularity of using Markovian methods to detect outliers in discrete sequence, we decide to employ rule-based models~\cite{aggarwal2015outlier} for two reasons.
First, Markovian methods are a black box and the resulting outlier values are sometimes difficult to comprehend. Second, the experts have explicitly described two types of iterations they are very interested in, namely, those iterations when many images with values that remain stable for many previous iterations suddenly flip (denoted by the \textit{left-rule}) and those iterations when many images flip and keep their values stable after many iterations (denoted by the \textit{right-rule}).
Fortunately, these anomalies can be easily modeled using rules.
The rule-based models primarily estimate the value $P(a_i|a_{i-k},\ldots,a_{i-1})$, which can be expressed in the following rule form: $ a_{i-k},\ldots,a_{i-1} \Rightarrow a_{i}.$
In our scenario, if an image has the same value (either 0 or 1) in the previous consecutive $k$ iterations ($i-k,\ldots, i-1$), then its value must be the same at iteration $i$ (the left-rule).
Otherwise, iteration $i$ is considered an outlier for the specified image.
Based on these considerations, we develop an application-specific algorithm to detect anomaly iterations in the validation history. The algorithm includes the following steps:
\item{\textbf{Rule-Judgement}:} ~The algorithm computes a vector $[l_{i1}, \ldots, l_{in}]$ for every image $i$, where $l_{ij} =1$ if the left-rule is satisfied, otherwise, $l_{ij} =0$;% is judged by checking whether left-rule at iteration $j$ is satisfied. If satisfied, $l_{ij} = 1$ and otherwise $l_{ij} = 0$.

\item{\textbf{Aggregation}:} ~For each class that contains $m$ images, the algorithm aggregates all the computed vectors for each image into one $[L_1, ..., L_n]$, where $L_j = \sum_{i=1}^{m}l_{ij}$, \ti{denoting the left anomaly score at iteration $j$ for this class.}
\end{compactenum}The approach is a window-based method, and the experts can adjust the window size $k$ to control the sensitivity of the anomalies.
In a similar manner, we detect the anomalies from the opposite direction for the right-rule.

The Layer View focuses on weight-related tasks (\textbf{R1}, \textbf{R2}).
The view consists of two connected parts, namely, the CNN structure and the hierarchical small multiples (Fig.~\ref{fig:layer_view_illustrator}), so that experts can hierarchically explore and compare various types of statistic in the context of the network structure.

	\centering
	\includegraphics[width=0.95\columnwidth]{resources/layer_view_illustrator}
	\vspace{-2mm}
	\caption{Visual encodings in the Layer View: (a) a CONV layer, (b,d) hierarchical bars, (c) links between the CNN structure and (e) the hierarchical small multiple charts, (f) a pixel chart for one layer.}
	\label{fig:layer_view_illustrator}
\end{figure}\textbf{CNN structure}.
The experts hope our tool can help them explore the statistical information of each layer and meanwhile know their relative positions in the entire network (\textbf{R1}).
Thus, we adopt Netscope\footnote{Netscope is a web-based tool for visualizing neural network architectures. \url{http://ethereon.github.io/netscope/}}, a popular neural network visualizer, in our system.
\ti{
The green rectangle is data input layer, the red ones are the CONV layers, and the purple ones mean the pooling layers.
The links between these rectangles show the network structure.
We further add blue level bars (Fig.~\ref{fig:layer_view_illustrator}b) to encode the latent hierarchy (from CONV modules, bottlenecks to basic CONV layers, Sec.~\ref{sec:dataprocessing}).
}
The right most level bars represent CONV modules (Sec.~\ref{sec:systemoverview}), which are recursively divided into smaller level bars until reaching elementary CONV layers (i.e., red rectangles).
To assist experts in exploring and comparing layers of a deep CNN (\textbf{R1, R2}), a space-efficient visualization technique is demanded.
Thus, we leverage hierarchical small multiples to show layers of interest (Fig.~\ref{fig:layer_view_illustrator}e).
\ti{By default, experts are presented with the information about CONV modules and then can drill down to see more information about low-level CONV layers with interactions with the network graph (i.e., click on the corresponding level bars).
The width of outcropping rectangles (Fig.~\ref{fig:layer_view_illustrator}d) encodes the aggregation level of current layer charts. For example, the top second layer chart in (Fig.~\ref{fig:layer_view_illustrator}e) shows the bottleneck-level aggregation information and the following three layer charts show the basic CONV layer level information. Besides, the links (Fig.~\ref{fig:layer_view_illustrator}c) mark the real positions of the layer charts in the network structure.
}

The small multiples support multiple types of charts including line chart, horizon graphs~\cite{heer2010tour} and box plots to emphasize the different aspects of the statistical data.
The experts use box-plots to see the rough distribution of statistical values and use basic line charts to examine individual values. Besides, the experts prefer to use horizon graphs when performing tasks in regard to trend tracking and comparison (\textbf{R2}), because of its effectiveness in visualizing divergent weight values~\cite{javed2010graphical}.
Similar to unfolding the class heatmap to a pixel chart, the experts are also allowed to open the layers of interest as a pixel chart (Fig.~\ref{fig:layer_view_illustrator}f) that presents the filter-level information (\textbf{R1}). Each row (1px height) in the pixel chart represents one filter, and each column (1px width) indicates one iteration. We use sequential colors to encode pixel value (e.g., the cosine similarity between two subsequent dumped iterations).
In particular, the experts want to understand further how the changes in network parameters are related to class performances (\textbf{R6}).
For example, several anomaly iterations may be detected for a single class.
For each detected anomaly iteration, we can identify a set of \textit{anomaly filters} (i.e., the top $k$ filters with largest changes at that iteration).
Since different classes may share anomaly iterations and different anomaly iterations may share anomaly filters, are there any filters that are commonly seen in these iterations?
Do any of the anomaly classes or filters strongly co-occur?
We designed the Correlation View to answer these questions.
	\SetAlgoNoLine
	\KwIn{Target set $S_{target}$.}
	\KwOut{Minimum partition for $S_{target}$.}
	$S_{result}$ = $\emptyset$\;
	\For{each target set $s_t$ in $S_{target}$}{
		$S_{new}$ = $\emptyset$\;
		\For{each mini set $s_r$ in $S_{result}$}{
			$itersection$ = $s_t \bigcap s_r$\;
			$S_{new}$ = $S_{new} \bigcup intersection \bigcup (s_r - s_t)$   \label{alg:setsplit:split}\;
			$s_t$ = $s_t - s_r$\;
		}
		\If{$s_t$ is not empty}{
			 $S_{new} \bigcup s_t$\;    \label{alg:set:addremain}
		}
		remove all empty set in $S_{new}$\;
		$S_{result}$ = $S_{new}$\;
	}{\bf return} $S_{result}$ \label{alg:setsplit:return}

\caption{Minimum Set Partition}
\label{alg:setsplit}
\end{algorithm}%\setlength{\textfloatsep}{5pt}%}%\end{spacing}%\vspace{-3mm}\textbf{Filter set partition}.
We first introduce the \textit{mini-set} concept to organize anomaly filters that are shared by multiple anomaly iterations and different classes.
For each class $C_i\in\{C_i|{1\leq i \leq n}\}$, we denote its anomaly iterations by $T_i = \{t_{i,k}|{1\leq k\leq n_i}\}$.
Thus, all anomaly iterations are $\cup_{1\leq i \leq n}T_i$, denoted by $T$.
For each anomaly iteration $t\in T$, we denote its anomaly filters at CNN layer $L_j\in\{L_j|{1\leq j \leq m}\}$ by $s_{j,t}$.
Thus, for each layer $L_j$, we can collect all anomaly filter sets $\{s_{j,t}|t\in T\}$ (denoted by $S_j$)  and all anomaly filters $\cup_{t\in T}s_{j,t}$ (denoted by $s_{j}$).
Thus, mini-set aims to find a minimum set partitions of $s_{j}$ (denoted by $s_j^\ast$) that each $s_{j,t}$ can be assembled from some elements (i.e., mini-sets) in $s_j^\ast$.
We specifically propose a Set Partition Algorithm (Alg.~\ref{alg:setsplit}) to find $s_j^\ast$.
The algorithm accepts a target set as input (i.e., $S_j$). $S_{result}$ is initially empty and a new anomaly filter set is used at each time to partition the mini-sets contained in $S_{result}$ (cf. lines~4 to 7). If the new anomaly filter set is not empty after partitioning, then it is added as a new mini-set (cf. line~8). Finally, the partitions contained in $S_{result}$ will be returned.

\begin{figure}[t]
	\centering
	\includegraphics[width=1\columnwidth]{resources/correlation_view}
	\caption{ (a) The abstract version of correlation view, where rows and columns represent layers and image classes, respectively. A sequential color scheme is used to encode the number of anomaly filters. (b) The complex version of correlation view, where the detailed information of individual anomaly filters are shown. (c) A layout solution for coordinated analysis without using skewed axes. }
	\label{fig:correlation_view}
\end{figure}%(cf. line~\ref{alg:klocations:7})%, can help experts discover strong relationships between layers, classes, and anomaly iterations. \ww{mention alg 1}%To construct the Correlation View, we first introduce a concept of \textit{mini-set}.%Correlation matrix provides an overview for exploring the relationships between the layers or filters and the classes. To identify which filters in one layer change most hugely for many different identified abnormal iterations of some classes. Here we first introduce a concept \textit{mini-set}. For each abnormal iteration of each class, we denote the set of filters in layer $L_i$ that change most hugely as $s_{t_j}$. Our purpose is to find minimum number of exclusive sets of filters, with which each $s_{t_j}$ can be assembled. For example, there are three sets, $[1,2,3]$, $[1,2]$, and $[3]$. Thus, the minimum number of exclusive sets should be 2, that is, $[1,2]$ and $[3]$, as all the three sets can be represented as union of some of them. These exclusive sets are denoted as mini-sets.\textbf{Visual encoding.}
To intuitively represent these relationships, we introduce a grid-style visualization (Fig.~\ref{fig:correlation_view}), where rows and columns represent layers and image classes, respectively. The number of rows and columns equal to the number of layers with anomaly filters and classes with anomaly iterations, respectively.
\ti{
We start from a abstract version.
In this version (Fig.~\ref{fig:correlation_view}a), for $\mathrm{Cell}_{i,j}$, a sequential color scheme is used to encode the number of anomaly filters ($\cup_{t\in T_j}s_{i,t}$).
The darker the color it is, the more anomaly filters appear in layer $L_i$ that are related to class $C_i$.
From this visualization, we can easily observe the correlations between layers and classes, while it also hides much detailed information.
We cannot answer questions like whether the filters in $\mathrm{Cell}_{i,j}$ are the same with $\mathrm{Cell}_{i,k}$ (this kind of information shows how many classes this filter can impact and help examine the relationships among classes), or whether there are filters in $\mathrm{Cell}_{i,j}$ appearing in more than one anomaly iteration (this shows the importance of these filters for class $C_j$).
}

To solve these problems, we provide an advanced version (Fig.~\ref{fig:correlation_view}b).
For $\mathrm{Cell}_{i,j}$, the width and height encode the number of anomaly iterations and the number of anomaly filters of the corresponding class and layer (i.e., $|T_j|$ and $|s_{i}|$), respectively.
Based on these numbers, the columns and rows are further divided with vertical/horizontal lines.
For a class (e.g., $\mathrm{Column}_{j}$), $|T_j|$ vertical lines are drawn to represent all related anomaly iterations (i.e., $[t_{j,1}, t_{j,2},\ldots,t_{j,n_j}]$).
For each row of layer $L_i$, there are  $|s_i^\ast|$ horizontal lines representing all mini-sets in that layer.
The intersections between these horizontal and vertical lines are highlighted with blue rectangles if the corresponding mini-set is part of the anomaly filters of the corresponding anomaly iteration.
The height of the rectangles represents the number of filters of the corresponding mini-set.
\ti{Obviously the introduction of mini-sets dramatically cuts down the number of horizontal lines and blue rectangles, otherwise each anomaly filter require one horizontal line and one rectangles, which may cause serious visual clutter problem. In fact, mini-sets can be viewed as a partially aggregation version instead of representing all the anomaly filters as horizontal lines and rectangles.
Users can set the minimum appearing number of mini-sets to filter the sets with lower importance.}%\tii{Give some example patterns about the importance of filters, or the classes internal correlations.}%The horizontal lines's widths equal to the corresponding mini-set size and opacity is used to encode the value that is computed by multiplying the mini-set size and the the used times of this mini-set (denoted as \textit{Correlation Degree}). Thus, for the one with low correlation degree, it will become transparent.%With this design, experts can easily discover the distributions and correlations between filters and classes by using this grid-style visualization.%For example, experts can easily follow these lines to discover those layers/filters that are related to certain classes.%\ti{Beyond that, we also provide the experts with a simple version (Fig.~\ref{fig:correlation_view}b) to only uncover the correlation between layers and classes while hiding the relationships across classes and the iteration-related information. In this version, for $\mathrm{Cell}_{i,j}$, a sequential color was used to encode the number of filters ($\cup_{t\in T_j}s_{i,t}$). The size of inner rectangle represented the number of filters shared by all $s_{i,t}$ in $T_j$.}%The rows and columns of correlation matrix represent layers and image classes, respectively. The width and the height of $Cell_{ij}$ encode the number of abnormal iterations identified for class $C_j$ and the number of filters contained in layer $L_i$.%Inside the cell, there are several rectangles representing the filters that changes most hugely.%For the $Cell_{ij}$, it is further divided into sub-rows and sub-columns, each sub-row indicting one mini-set of filters (at least one) and each column representing one detected abnormal iteration.%If there is one mini-set of filters in layer $L_i$ that changes most hugely for one the abnormal iteration of class $C_j$, a rectangle will be drew on the corresponding sub-row and sub-column in the $Cell_{ij}$. The height of the rectangle suggest the number of filters contained in the minimum set. The vertical edges link all the filters that changes most hugely in one abnormal iteration for one class. The horizontal edges link all the same mini-set of filters in one layer for each class.%\textbf{Design consideration}.%This view has been iteratively re-designed several times with the discussions of the experts.  We can choose to only encode the number of anomaly filters appearing %The major concern is the tradeoff between abstract and detail.%Inspired by MatrixWave~\cite{zhao2015matrixwave}, the cells of layer-class matrix initially were designed to have the same width and height (Fig.~\ref{fig:correlation_view}b). For $\mathrm{Cell}_{i,j}$, a sequential color was used to encode the number of filters ($\cup_{t\in T_j}s_{i,t}$). The size of inner rectangle represented the number of filters shared by all $s_{i,t}$ in $T_j$. We also considered to use glyphs (Fig.~\ref{fig:correlation_view}c) to show the number of each group of filters that are grouped by the co-occurrence times. Although this method reveals the correlations between layers and classes and can identify the number of most critical filters in one cell (the ones shared by most $s_{i,t}$ in $T_j$), it fails to disclose the inner relationships between classes and to help the experts identify the critical filters. %The experts dislike it.%Then, we designed a second version of Correlation View, which was partly inspired by UpSet~\cite{lex2014upset}. For this version, we did not apply partition algorithm to divide $s_j$ into mini-sets, but rather drew a horizontal line for each filter. Although this design can reveal the correlation between classes and anomaly iterations in great detail, this design encountered a serious visual clutter problem. In the end, we adopted the set partition algorithm to aggregate individual filters and to reduce the number of horizontal lines while preserving the desired information. %One more advantage of such aggregation is that the line's width and opacity channel can be further utilized to encode the importance of mini-sets.%Eventually, we adopt the design shown in Fig XX..\subsection{Cube Visualization}\label{sec:cubeview}%\dy{space-efficient, visualize all components in one screen to enable users to conduct coordinate analysis. Usually 3D is not preferred for information  visualization  duo to occlusion  and perspective  distortion. But our cube design does not have these  problems... Skewed axis. Justify: 1) limited display space 2) correlation understanding 3) sharing the same time axis by skewed axis method~\cite{berry2004binx}.}

The log data contain three main aspects of information, namely, iterations, validation information, and weight information.
The three aforementioned views are designed to show all possible 2-combinations of these three types of information, respectively.
\ti{
Although these views can be used individually, they need to be combined together to form a complete picture.
}
Thus, we propose a novel and intuitive visualization technique, which naturally and seamlessly stitches the three views together, based on their shared axis (inspired from Binx~\cite{berry2004binx}), into a ``cube'' shape (Fig.~\ref{fig:teaser}).
When experts find or highlight a pattern of interest, they can easily track the pattern over the edges to find the related information in the other two views easily.

\ti{
The use of skewed axes may bring about a possible perspective distortion problem. Nevertheless, the advantages of the cube-style design far outweigh the disadvantages.
Given the limited pixels in a computer screen and each view requiring a large display space, the experts all agree that the cube-style design is the most space-efficient and intuitive manner to show all the information. Furthermore, with such design, it prevents the experts from switching from multiple views, reducing the cognitive burden and the load of memory.
This allows the experts to conduct correlation analysis more effectively.
We also provide a compromised solution to handle the distortion problem, that is, laying out the three views in the form like Fig.~\ref{fig:correlation_view}c. So the experts can firstly examine the layer view (horizontally) or validation view (vertically) together with the correlation view, and then switch to cube mode to explore the three views together.
}\ti{
Notice that there are some different settings for several views in the cube.
For the layer view (front), only the layers with anomaly filters are activated (see the activated blue bars in the front view of  Fig.~\ref{fig:teaser}), the weight variation of each anomaly filter is represented as a horizontal color strip.
For the validation view (top), only the classes with anomaly iterations are preserved.
The following lists several common exploration pipelines:
\begin{compactitem}
	\item P1: from the layer view (front), we can quickly check the distribution of activated layers in the overall network and pick some anomaly filters of interests. Then, by tracking along the horizon axis to the correlation view (right), we can examine which classes these filters impact and how important these filters are to the classes. Finally, we can observe the evolving patterns of these classes and the corresponding anomaly iterations in validation view (top).
	\item P2: from the validation view (top), we can firstly mark several anomaly iterations of some classes. Then, we can check the corresponding columns in the correlation view, finding the rows that contain anomaly filters and exploring the importance of these filters to these classes and how these filters impact the other classes. Finally, by highlighting these corresponding rows, we can observe them in the layer view to see how these filters behave around the picked anomaly iterations.
	\item P3: from the correlation view (right), we can search the horizontal lines across many rectangles (it means these filters impact many classes at the same time) or the rectangles that appear more than one time in the same cell (these filters are judged as anomalies many times for a class and may have great impact on this class). With these selected horizontal lines or rectangles, we can simultaneously track their corresponding weight variation information in the layer view (front) and class performance information in the validation view (top).
\end{compactitem}
}%For example, experts may click on one or more mini-sets of filters on the Correlation ``surface,'' then our system automatically highlights the related classes and layers on the other two ``surfaces'' to help experts examine the error rates of these classes, anomaly iterations, and filter change patterns and positions in the CNN structures at the same time.%We admit that there exists a possible perspective distortion problem for the use of skewed axises, the advantages of the cube-style design, however, far outweigh the disadvantages. %\ti{Given the limited pixels in a computer screen and each view requiring a large display space, the experts all agree that the cube-style design is the most space-efficient and intuitive manner to show all the information. Furthermore, with such design, it prevents the experts from switching from multiple views, reducing the cognitive burden and the load of memory.%This allows the experts to conduct correlation analysis more effectively.}%\dy{One slightly different in cube view is that, the heights of each small multiples of Validation View (top face) and Layer View (front face) are brought into correspondence with related cell's height and width in Correlation view (right face). Besides, the small multiples for layers in front face are replaced with color stripes, each representing the change pattern of one anomaly filter (the height and vertical position are consistent with the one in Correlation view). Since all the opened layers are basic CONV layers, only the smallest blue bars that exist anomaly filters are highlighted. }%Thus, the cube consists of three faces: the top face is the validation view. It is to be noted that the height of each heatmap equals to the width of corresponding column in correlation matrix now, suggesting the number of abnormal iterations. Besides, the timeline is attached on the top the top face; the front face shows the layer view, where the height of each layer equals to the height of corresponding row in the correlation matrix as well; the right face is the correlation matrix. When the experts scoll in the right face, the front face and the top face will scoll too to ensure the positions of layers and classes can match the correlation matrix in the right face.%Although the aforementioned three views can be explored individually to find interesting patterns, they all share dimensions%To further understand the patterns found in the correlation matrix, the experts often need to switch to validation view and layer view. To reduce the cognitive burden on working memory, we propose a novel cube-style visualization technique that can intuitively integrate the three proposed views together to help the experts explore the complex relationships among the multiple types of heterogeneous training data (neuron weights, validation images, and training iterations). The cube consists of three faces: the top face is for the validation view. It is to be noted that the height of each heatmap equals to the width of corresponding column in correlation matrix now, suggesting the number of abnormal iterations. Besides, the timeline is attached on the top the top face; the front face shows the layer view, where the height of each layer equals to the height of corresponding row in the correlation matrix as well; the right face is the correlation matrix. When the experts scoll in the right face, the front face and the top face will scoll too to ensure the positions of layers and classes can match the correlation matrix in the right face.%\subsection{Interactions}%Many useful interaction techniques are integrated in \name.%%\textbf{Details on demand.} \name supports the interactive exploration on the training log from different levels of details.%Hierarchical small multiple, open in needs.%Both the class heatmap and layer chart can be flipped into pixel charts for showing more detailed image level and s level information, respectively.%Clicking on pixel, show image.%%\textbf{Chart zoom in/out.} There are two types of zoom operations on charts. First, the pixel chart of image or layer supports horizontal and vertical zooming. Take the image pixel chart as an example, the horizontal zoom in/out (increase/decrease) the width of each cell (i.e., iteration) and the vertical zoom in/out (increase/decrease) the height of each cell (i.e., image). This allows the experts the pixel charts in high resolutions. Besides, zoom in/out also works on hierarchical small multiple chart for layers, allowing the experts expand/shrink the height of charts.%%\textbf{Correlation analysis.} Both validation view and layer view share the same timeline. When the experts hovering on class heatmaps, layer charts, or pixel charts, a dashed vertical line will show up to help the experts . Iteration marking, 3D transforming. With all the aforementioned interactions, a coordinated analysis can be performed efficiently and effectively.%\textbf{Selecting, filtering, highlighting.}%\subsection{Interactions}%\label{sec:interactions}%Generally support some interactions. Hover, sync line! Sync zoom and pan. Highlight. %filtering:%aggregation:%validation view -> keep the classes with anomaly iteration. %For the remaining classes, use clustering algorithm and then aggregate classes in on cluster.%layer view -> keep the layers with anomaly filters.%For filter change degree vis, use the clustering algorithm to aggregate .%correlation view -> keep the filters appearing in many classes (column), remove the mini-set with very small size and appear in very few classes.%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Use Examples}\label{sec:evaluation}%caseSHOWEXPLORE
We derived these examples through the assistance of our collaborating experts, who were familiar with our designs and data. As a remark, the following results are from the experiment with 8 times larger batch size and learning rate setting than the basic setting introduced in Sec.~\ref{sec:dataprocessing}.

\subsection{Exploring Validation Results}%\begin{figure}[htbp]%	\centering%	\includegraphics[width=0.48\textwidth]{resources/validation}%	\caption{(A) Overview of all classes. (B) A radial location glyph to present a selected billboard location. (C, D, E) show the alternative solution glyph designs.}%	\label{fig:case1}%	%\vspace{-2mm}%\end{figure}\begin{figure}[htp]
	\centering
	\includegraphics[width=0.8\columnwidth]{resources/case1-1}
	\vspace{-2mm}
	\caption{Overview of validation classes. (a) Two curves show the overall training/validation error rate. (b) Two turning points align well the boundary of stage $s2$. (c) Three peaks appear in the stage $s1$ and align well with (f) the detected anomaly iterations. (d) Two types of mushroom images have different behaviors in the class. (e) Most images in the class flip at the anomaly iteration.}
	\label{fig:case1}
\end{figure}
The first scenario demonstrates how the experts use \name to explore the image classification results (\textbf{R3}, \textbf{R4}, and \textbf{R5}).

Fig.~\ref{fig:case1}a shows a typical visualization of training/validation errors that may appear on any popular training platform. The timeline at the top shows a total of 1.2 million iterations.
Beneath the timeline, four line segments represent four stages ($s1$, $s2$, $s3$, and $s4$ in Fig.~\ref{fig:case1}) in the training process, \dy{where the later stage has one-tenth of the \textit{learning rate} of the previous stage.}%which are decided by the hyper-parameter of \textit{learning rate}. %In our case, the learning rate of later stages is only one tenth of the previous stage's.}
We can observe that two sudden drops in the curves match well with the boundaries of the training stages (Fig.~\ref{fig:case1}b).
However, this is a well-known pattern to the experts.
On the other hand, although the overall error rate continues to decrease, the class-level error rates show a more complicated story, that is new to the experts.
By quickly scanning the small multiples in cluster-level, the experts identify there are generally four types of class evolving patterns (Fig.~\ref{fig:case1-2}).
From top to bottom, the four types are more and more difficult to train.
\ti{For example, for the type at the top, these classes are recognized correctly after a few iterations.
By contrast, the classes at the bottom always have high error rates in the entire training process, which means that the resulting network fails to recognize the related images.}
From this, the experts learn that the model has spent most of time to improve its performance on the classes of middle-level classification, since the model has already performed well on the easy-trained classes at a very early stage and is always performing miserably on the hard-trained classes over the entire training.
From these patterns, the experts consider it promising to accelerate the training process and improve the overall performance by treating classes differently during the training process. That is, stop feeding the easy-trained classes in an appropriate early stage, put more efforts on training the classes of middle difficulties for classification, and figure out why some classes always have extremely high error rates. One similar attempt has been made in a recent work~\cite{lin2017focal}.

The experts are curious about the three sudden peaks in stage $s1$, and then mark these three iterations with dotted lines (Fig.~\ref{fig:case1}c), which look like anomaly iterations (\textbf{R4}).
However, the colors in the small multiples do not have clear patterns related to these iterations.
Then, the experts turn on the anomaly detection and immediately find that many triangles are aligned well with the dotted lines (Fig.~\ref{fig:case1}f), thereby confirming our suspicion.
Then, the experts can click on the corresponding image icons to see the detailed images that contribute to the three peaks.
In addition, there are more anomaly iterations in stage $s1$ then in the later stages.
This interesting pattern can be explained by the reduction of learning rate and the convergence of the model in the later stages. At the same time, it also implies that the learning rate in stage $s1$ is slightly too high, leading to the instability in the model (the case in Sec.~\ref{sec:case2} indicates the same finding for the discovery of potential ``dead'' filters).
To further examine what happens at the anomaly iterations for a class, the experts can further check the image-level information of the class (\textbf{R5}).
For example, the experts are curious about the abnormally large anomaly iteration in the class of ``mushroom'' (Fig.~\ref{fig:case1}d) that are captured by both the left-rule and the right-rule.
Then, they click and expand color stripe to see the pixel chart of images.
First, they confirm that this iteration is indeed special for this class, because nearly all images flip during particular that \dy{dumped interval} (Fig.~\ref{fig:case1}e).
Thus, they may further investigate to find the layers or filters that cause such flips based on the filter updates around that iteration.
\dy{In particular, the experts comment that, it seems that after the iteration, the CNN model has jumped to a better local optimal for the class, because the green color is more stable after the iteration.
This may result from the reduction of the learning rate (from $s1$ to $s2$).
This kind of patterns appear frequently in many classes during the whole training process, many of them occurring not in the learning rate transition point.
The experts wonder that the model should be trying to jump from one local optimal to another better local for these classes continuously, so as to reduce the overall error rate gradually.}
This insight has never been obtained because the experts initially thought that the error rate for one class should decrease steadily.
Besides, the experts also find that, at the bottom of the pixel chart, several images are mislabeled in the entire training process, although the class is easy to train overall(Fig.~\ref{fig:case1}d).
To understand why, the experts click on these images to examine them, and find that the contents in the mislabeled images have a clear color pattern different from that of the rest of the mushroom images.
The correctly labeled mushrooms are all red, while the mislabeled ones are white or orange.
This finding indicates color is a critical feature that the CNN has learned to classify this class of images.
	\centering
	\includegraphics[width=0.98\textwidth]{resources/case2-1}
	\caption{(a, b, c) The sd values of each layer decrease slowly and have different scales in different CONV modules. (d) The weight changes in filters are large at the beginning. (e) One outlier filter is detected, whose weights never change during the entire training process.}
	\label{fig:case2-1}
	\vspace{-2mm}
\end{figure}
This scenario shows how to discover patterns in neuron weights via the Layer View (\textbf{R1}, \textbf{R2}).
First, the experts choose to show the sd (standard deviation) of the weights at the layer-level using horizontal graphs (Fig.~\ref{fig:case2-1}).
As the experts expected, all the trends show a similar pattern of slow decrease, indicating the weights in the entire model is converging over iterations.
Besides, the experts also find that deeper layers (closer to the loss layer) tend to have smaller sd values.
\dy{In particular, by tuning the band number (finally to 3) of the horizon graphs, they found the sd values of a CONV module are usually twice as large as those of the one below it (a, b, and c in Fig.~\ref{fig:case2-1}).
Given that we apply Xavier initialization\footnoteref{note7} and for ResNet-50, the input sizes of layers in a CONV module are twice as large as the ones in the layers of its previous CONV module, the observed result is not beyond the experts' expectation. This suggests that there is no problem exist on the initialization approach.
}%where the hyper-parameter sd depends on its size of inputs from the previous CONV layer and .%The experts  the weights in a CONV layer are initialized according to the size of inputs from the previous CONV layer (i.e., Xavier initialization~\cite{glorot2010understanding}). %the numbers of neurons in the layer.%Since layers from neighboring big CONV layers often have very different numbers of neurons, the weights may also different values.%Since neurons are generally doubled between big CONV layers, we%To compare their trends, the experts normalize them individually.%Initially, each horizon graph has its own scale (i.e., min value and max value are computed each layer) to facilitate the individual layer trend analysis (\textbf{R1}).%Fig.~\ref{fig:layer_view} shows the std values of layers at different levels of hierarchies. Initially, each horizon graph has its own scale (i.e., min value and max value are computed each layer) to facilitate the individual layer trend analysis (\textbf{R1}). As observed by the experts, the std values have very similar evolving patterns for each layer and become gradually smaller and smaller over the training, indicating the weights of model converge over training.%To make comparison among them(\textbf{R2}), they switched the scale of each horizon graph to the same max and min (computed globally), finding that the deeper layer has smaller std. In particular, by tuning the band number of horizon graph, they found the std values of the previous big CONV layer are nearly twice as much as the next big CONV layer (Fig.~\ref{fig:layer_view}).%However, there is no clear difference when comparing the layers that belong to the same big CONV. This is what the experts expected, because the experts adopted different initialization settings for different layers. Specifically, the layers with more number of neurons (i.e., the number of learnable weights) should be initialized with a smaller std. Basically, the layers in the next big CONV layer have twice number of learnable weights than current big CONV and there is no big difference of the number of weights for the layers belonging to the same big CONV layer. Thus the experts deemed that the training goes on a right direction regarding initialization methods.

Analogously, the experts find that the weight means of each layer become negative quickly (from green to blue instantly, Fig.~\ref{fig:case2-2}a) except for the FC layer (Fig.~\ref{fig:case2-2}b).
At first, the pattern looks strange to the experts.
Then, the experts realize that it is reasonable to have more negative weights than positive ones, since negative values are often used to filter out trivial features owing to the use of ReLU activations.
The increase of negative weights suggests that the network is trained to extract useful information from the original image layer by layer, and then finally remain the most relevant features.
\dy{As for the FC layer, it plays a function of shaping the extracted useful features into feature vectors of given dimension for further classification. One strange phenomenon intrigues the experts, that is, the FC layer weight means are always positive in many-times training ResNet-50 (with different batch sizes and learning rates) on ImageNet Dataset, whereas becoming negative when training ResNet-164 on Cifar Dataset~\cite{krizhevsky2009learning}. This finding is worth a further investigation.}%As for the FC layer, it plays a function of shaping the extracted useful features into a given dimension feature vector.  The experts }%Every neuron plays as a small classification function detecting certain kind of feature instead of merely the FC layer. It is still confusing why other layers have more negative weights while FC layers have more positive weights. Actually, Weights in a CNN form feature detectors, so that a certain pattern in a image is connected to strong weights, but the rest of the image pixels should not cause any activations in the next layer neurons. Only a small fraction of neurons in a layer is activated every time an image is shown, and a small fraction of weights is needed to be large to activate (or suppress) any particular neuron. Moreover, the number of patterns a network needs to detect is fairly small, especially in the early layers. Therefore, overall connectivity for the network is usually very sparse. The distribution of FC layer (pos more than neg) is still unknown.})%(\dy{every resnet model, final layer has more postive values. Cifar is different - always negative})%The experts never notice this and later they explained that it is reasonable that the negative values are more than positive value, as the function of negative values is to filter the trivial features. The more negative values for CONV layers suggest they are extracting useful information from the original image layer by layer and then finally remain the most relevant features for classification. Since the FC layer function as a classification function, it also normal that its mean is not negative.%\textbf{Filter level exploration}.
Apart from layer-level values, the experts also explore the filter-level information (\textbf{R1}).
In our system, two different ways (i.e., filter-based or iteration-based) are used to normalize weight changes at the filter-level.
For filter-based normalization, changes are grouped and normalized by filters, which aims to help experts see the change distribution over iterations for individual filters.
Similarly, iteration-based normalization allows experts to examine the distribution over filters for individual iterations.
For example, Fig.~\ref{fig:case2-1}d visualizes the filter changes in one of the CONV layer belonging to the second CONV module using filter-based normalization.
The experts find that the changes are drastic in stage $s1$ and become relatively small in the later stages because of the decrease in learning rate and the convergence of the model.
However, the experts also identify two strange filters among 64 filters in the first CONV layer that have a constant deep blue color (Fig.~\ref{fig:case2-1}e).
By further checking, the experts find that the weights of these two filters never change during the entire training process.
	\centering
	\includegraphics[width=0.98\textwidth]{resources/case2-2}
	\caption{(a, b) The means of weights in each CONV layer become negative quickly (from green to blue) except for the FC layer. (c) Three filters are always more actively changed than the other filters in the later part of training progress.}
	\label{fig:case2-2}
	\vspace{-4mm}
\end{figure}\dy{This is a total surprise to the experts. Excluding programming bugs, the most likely reason should be due to the dying-ReLU problem, namely, these two filters are inactive for essentially all inputs and no gradients flow backward through the neurons of the two filters.  The experts suspect the dying-ReLU problem results from the high learning rate in the beginning of train. In fact, the experts usually follow a rule of thumb to set the hyper-parameter learning rate, that is, multiply the learning rate by k if the batch size is multiplied by k. This rule is currently formally introduced in a recent work~\cite{goyal2017accurate}.
In this experiment, we use 32 times larger batch size GPUs (32 GPUs) than the mini-batch size 32 for one GPU to train the model with the corresponding size of learning rate, dying-ReLU problem still occurs. This reminds the experts that the rule may not so accurate for extremely large batch size sometimes, but the problem can be solved by carrying out a warmup strategy (i.e., using lower learning rate at the start of training~\cite{he2016deep}), which the experts haven't done in previous trainings. One further interesting finding is that by inactivating these two "dead" filters (i.e., set their weights as 0 so that they are inactive for any inputs), the experts find the overall performance not affected at all, whereas if we inactivate other random-picked filters in the first CONV layer of the model, the number of mislabeled images in $D_v$ would increase few thousands.
Thus, the experts finally modified the network configure and eliminated these two filters, so that the model can run faster while costing less memory.
}

Fig.~\ref{fig:case2-2}c visualizes the weight changes in one middle layer using iteration-based normalization.
The experts find that a small number of filters are always more actively changed than the other filters (long deep blue lines in Fig.~\ref{fig:case2-2}c) in the later part of iterations.
This pattern implies that the updates inside a layer may be highly divergent.
\dy{In the later part of the training, where the learning rate is getting smaller and the model is converging, only a couple of filters are still continually actively updated for every iteration.
We have tried to inactivate these identified filters, the result showing that the overall performance is not affected.
It is not beyond the experts' expectation due to the ResNet's ensemble-like behavior~\cite{veit2016residual} (even several entire layers can be removed without impacting performance). In the end, the experts still cannot fully explain the behavior of these continually updating filters. One possible reason could be that these special filters are not trained well (not converge) to extract some specific features, thus reacting violently for every iteration even in the later stages of the training.}%It is strange because with the reduction of learning rate and the convergence of the model, the filter update r%The experts suspect that it may be a hint to reduce the amount of neurons in the layer (e.g., network compression~\cite{wei2016network}) (\dy{with the reduction of lr, update ratio should be very small, these three filters very strange! set them to 0 to see what happen}).%\dy{Multiple other important reasons could cause this phenomenon. For example, the reduction of learning rates, which influences the update step size per iteration, is highly likely the most important reason causing this result. Simply reducing neurons based on this hint is not reliable.}%Besides, with the vertical scale, the experts discovered that for some layers in the middle part of network, there are always few filters that change very hugely compared with the other filters at the same iteration (Fig.~\ref{fig:layer_view2}). This is never known by the experts. Accordingly, the experts considered that these filters are much more important than other inactive ones in the same layer, as they respond strongly for every fed images during training (just as the theory of use and disuse). This finding is significant for them to reduce the amount of parameters of a well trained CNN network (also known as network compression~\cite{wei2016network}).%(just as the theory of use and disuse, in the book ``on the origin of species''). This findings are significant for them to reduce the amount of parameters of a well trained CNN network (i.e., network compression~\cite{}, one of the hottest directions in AI filed).%Then, the experts used similar method to explore the mean magnitude (averaged sum of absolute value) of weights of layers, finding that the mean magnitude of each layer gradually converge to a small value and no exploded values occurred. These meet what the experts expected, suggesting there is no bugs in programming%To begin with, the experts indicated that different initialization methods are used to initialize weights on different layers. Basically, for the layers with more number of neurons (i.e., the number of learnable weights, equaling to filter width $\times$ filter height $\times$ current layer filter number $\times$ previous layer filter number), the initial std value should be smaller (more convergent).%To verify whether this initialization strategy take effects as their expecting, they turned to the layer view for help.%They were firstly shown with the std values of five big CONV layers plus a FC layer. Notice that each horizon graph has its own scale initially (i.e., min value and max value are computed each layer) to facilitate the individual layer trend analysis.%As observed by the experts, with the training, the stds of each layer has very similar evolving pattern and generally become smaller and smaller (\textbf{R2}), indicating the weights of model converge over training.%To make comparison among them(\textbf{R2}), they switched the scale of each horizon graph to the same max and min (computed globally), finding that the the deeper the layer is, the smaller the std is. In particular, the std values of current big $CONV_i$ layer are twice as much as next deep layer $CONV_{i+1}$.%They opened up CONV2 and one of the bottle-neck structure (3 elementary CONV layer) to further explore the difference of std for the layers belonging to the same big CONV. They found that there are no clear difference among these layers.%They explained that for the layers in the same big CONV layer, the number of neurons are almost at same scale while the next big CONV layer has at least two times of neuron number compared with current one. This well explains why the std value becomes smaller for deeper layer and remain same scale for the layers in the same big CONV layer.%Then, the experts used similar method to explore the mean magnitude (averaged sum of absolute value) of weights of layers, finding that the mean magnitude of each layer gradually converge to a small value and no exploded values occurred. These meet what the experts expected, suggesting there is no bugs in programming regarding to this two types of statistical value. The converging std and mean magnitude of weights can be also verified from the boxplot chart, where the values of min, 1/4 quarter, mean, 3/4 quarter, and max are shown each iteration. As shown in Fig., The five values tend to converge over training.%Similar exploration methods were used and the experts knew the weights tend to converge to mean of each layer with smaller std. Thus, they desired to see more about the mean of weights. From the fig. x, they found the means of each layer are becoming negative over training (blue encode negative value) except for the FC layer. The experts never notice this and later they explained that it is reasonable that the negative values are more than positive value, as the function of negative values is to filter the trivial features. The more negative values for CONV layers suggest they are extracting useful information from the original image layer by layer and then finally remain the most relevant features for classification. Since the FC layer function as a classification function, it also normal that its mean is not negative.%Besides, Std -> small (fig.), mean magnitude -> small. Also seen in boxplot view, show (conv1 boxplot). The experts told that for there is a strategy to initialize. Mean (fig. ).%\textbf{Model comparison}. We also trained resnet-164 whose structures are similar to resnet-50 but has 164 layers on cifar-10 dataset. Compare. Purpose.%Like the human brain, the areas that used most often will used most\subsection{Exploring Filter-Image Correlations}
In this scenario, we demonstrate how the experts use the Correlation View to explore correlations between images and filters.

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\columnwidth]{resources/n-teaser}
	\vspace{-4mm}
	\caption{
		A cube-style visualization that fuses three coordinated views together to reveal the rich dynamics in a CNN training process:
		(top) the Validation View shows the error rate changes of validation classes; (front) the Layer View shows the weight changes in CNN
		filters; (right) the Correlation View shows the potential relationships between filters and validation classes.
	}
	\label{fig:teaser}
	\vspace{0mm}
\end{figure}%In this case, the experts attempted to explore the correlation between validation images and neuron weights (\textbf{R6}).%There are two manners to explore such correlations.%For the first manner, the Validation View and Layer View are connected by sharing the same timeline. The experts can mark the iterations of interests in the Validation View. Then the vertical dashed lines running through both views will show up to help find abnormal changes regarding some statistic values. For example, at the anomaly iteration $i_1$ mentioned in Case 1, the experts found an exploded std value and max value occurred (with line charts) in the second CONV layer (the right side one with connection to CONV1 layer, Fig.~\ref{fig:layer_view2}). By further checking on the pixel chart, the experts identified two filters that change dramatically. Considering filters in shallow layers learn very fundamental visual features. Therefore, the experts inferred that the big changes of the two filters in the second CONV layer result in a huge impacts on lots of classes, leading to the form of the peak at $i_1$.%%For the first manner, the major purpose is to find how the layer statistical values correlate the error rates of classes. As the validation view and layer view are sharing the same timeline, the experts are allowed to mark the iterations of interests with vertical dashed lines running through both views and then conduct analysis accordingly.%%For example, the experts marked the abnormal iteration $i_1$, at which many classes detect outliers, and then switched to layer view with line charts (line charts are more good at conducing local tasks such as identifying the value at one iteration). They found the first basic CONV layer in the first bottleneck block of big CONV2 (i.e., the basic CONV layer after the CONV1 layer) has an exploded std value and max value with respect to the gradient at $i_1$.%%This indicates there should be some filters in this layer whose weights change hugely compared with others. By further checking filter-level pixel chart with vertical scale, they identified two dramatically changed filters, both changes very little in the previous many iterations. This suggests the features the two filters learned may have critical impacts on the classes that detect outliers at $i_1$, thereby leading to a peak of validation error rate curve.\textbf{Shallow-layer filters vs. deep-layer filters}.
Besides, Fig.~\ref{fig:correlation_view}a shows that deep CONV modules tend to contain more anomaly filters (especially for the CONV modules 4). The experts think that this kind of knowledge is of great importance for network compression~\cite{han2015deep}.
Then, the experts go to the complicated version to examine the more detailed correlation information.
They filter the mini-sets with very few appearing times, finding that anomaly filters in shallow layers are generally shared by more anomaly classes (columns) and iterations (vertical lines in one column) than those in deep layers (Fig.~\ref{fig:teaser}a).
The experts think that this pattern may relate to the fact~\cite{veit2016residual} that shallow-layer filters are more likely to capture basic visual features than deep ones, thereby the huge change of these filters affecting more classes of images (e.g., the long and opaque lines marked by b in Fig.~\ref{fig:teaser}).
By contrast, a deep filter tends to learn higher-level features, thus only relating to specific classes of images.}%Thus, the experts filter the Correlation View to show the filters that are related to more than one anomaly iteration (.}%Since the experts are more interested in co-occurring filters, they filter the Correlation View to show the filters that are related to %more than one anomaly iteration (Fig.~\ref{fig:teaser}c).%At the beginning, in the correlation view of Fig. X, each vertical line in one column (i.e., one abnormal iteration for the class this column corresponds to) lists top ten filters that changed most hugely (denoted as anomaly filters) at the detected abnormal iteration, where different anomaly iterations may share anomaly filters.%At first, by checking the network graph and the heights of each layer, they found there .%Since the experts paid more attention to the filters that co-occur in many abnormal iterations, they filtered the mini-sets that have few appearing times and contain few filters (if one mini-set's appearing times $\times$ containing number of filters is less than pre-defined threshold, then it is filtered).%The overall filter distribution shows that, although deep layers have much more filters than shallow layers, our algorithm detects more anomaly filters (i.e., the filters with largest changes at the detected anomaly iterations) in shallow layers.%In addition, anomaly filters in shallow layers are generally shared by more anomaly classes (columns) and iterations (vertical lines in one column) than those in deep layers.%Thereafter, just as shown in Fig.~\ref{fig:teaser}A, the experts discovered that although deep layers have multiple times of number of filters than shallow layers indeed, there are fewer deep layer bars are highlighted (i.e., have anomaly filters detected in this layer) than shallow layers. Besides, the height (number of anomaly filters) of deep layers (the interval distance between small circles in the right end of linking edges) seem to has no large difference compared with the shallow layers'. Both visual facts show that the filters in shallow layers have higher correlation degrees than the deep ones. In other words, the filters of shallow layers may learn some basic features that have impacts on many classes, whereas the features learned by the deep layers' filters may be more high-level and specific to very few classes. This conforms to the findings in prior work.%the height of deep layers decrease dramatically and some deep layer bars in the network graph are deactivated,%suggesting that a large number of mini-sets in the deep layers are filtered but few mini-sets in shallow layers are filtered.%Finally, as shown in Fig.~\ref{fig:teaser}A,%there are more shallow layer bars are highlighted (i.e., have anomaly filters in this layer) than deep layers and the height (number of anomaly filters) .%This suggests that the filters in deep layers learned more advanced features specific to one class and the filters in low layers (i.e., the layers close to CONV1 layer) are shared by many classes, which conforms with the prior knowledge.

To further explore the correlations,
the experts select two mini-sets (b1 and b2 in Fig.~\ref{fig:teaser}), for comparison. Both the horizontal lines of b1 and b2 are opaque and thick.
By tracking them in the Layer View and the Validation View, the experts can see that b1 is in the first CONV layer, and related to many classes.
The experts open these classes and discover that many images in them have a common feature, i.e., a large background of blue sky or ocean (b1 in Fig.~\ref{fig:teaser}).
This discovery suggests that these filters in E1 may target the basic pattern to help identify images that contain large blue areas.
By contrast, b2 is located at the fifth \dy{CONV module} and related to only three classes.
Interestingly, the images in the three classes also share a more concrete feature, i.e., objects in a bush (b2 in Fig.~\ref{fig:teaser}).
\dy{In short, this case confirms that we are on the right track to reveal how the model weight changes relate to the classification result changes.}%For B1, it is in the first CONV1 layer and occurs in many classes. These classes share common feature, namely, having natural scene as background either the blue sky or the blue ocean. This suggests these filters may learn some basic features (e.g., blue color) to help identify the images that have large blue area. However, for B2, it is in a very deep layer in big CONV5 and contains 7 filters that co-occur in three classes. Interestingly, these the images in the three classes share a very clear common concrete features, that is, flowers, pandas, and leopards in the bushes (Fig.~\ref{fig:teaser}C, xx). In particular, there are even some pandas found in the classes of leopards. The previous a series of explorations further showed the difference between filters in shallow layers and deep layers, that is, the filters in shallow layers tend to learn fundamental visual features and have higher correlation degrees (impacts on many classes), while the filters in the deep layers are on the contrary.%First, from the Validation View on the top face, the experts found For the images%and large rectangle height (3 filters).%This mini-set is shared by many classes and is in the CONV1 layer. By checking its relevant classes, the experts found all of these classes have one common feature, that is, having natural scene as background either the blue sky or the blue ocean, indicating the three filters may learned some basic features (e.g., blue color) to help identify the images that have blue sky or blue ocean as background.\textbf{Important filters for a class}.
To find stronger correlations between filters and classes, the expert focus on anomaly filters that appear more than once in a cell for a specific class.
For example, the experts find two appearances of the same mini-set (containing two anomaly filters) for the class of ``gong'' (c1 in Fig.~\ref{fig:teaser}).
Tracking horizontally (along with the pink-highlighted area), the experts find that the mini-set does not appear in other anomaly iterations, which also implies a strong correlation between filters in the mini-set and the class.
Then, the experts click on these two rectangular glyphs to highlight the corresponding iterations on the timeline (c2 in Fig.~\ref{fig:teaser}) and the filter locations in the Layer View (c3 in Fig.~\ref{fig:teaser}).
It is clear that the gong class is not a well trained class as it has a very large yellow area (indicate a relatively high error rate) in the Validation View.
However, the experts also find a period in the middle when this class has a relatively good performance (c4 in Fig.~\ref{fig:teaser}), which happens to contain the highlighted anomaly iterations.
Meanwhile, the Layer View shows that the highlighted filters are also updated dramatically during the period of good performance (c3 in Fig.~\ref{fig:teaser}).
Considering these patterns, the experts speculate that the filters in the mini-set have a strong impact on the classification of gong images.
As expected, we conduct experiments to inactivate these two filters, finding the overall performance and the performance on ``gong'' class are not impacted (see the reason in the last paragraph in Sec.~\ref{sec:case2}). Nevertheless, it provides the experts with a new manner to investigate the functions of filters co-working together for classifying one class of images. That is, increase the threshold to find anomaly filters as many as possible, find the mini-sets containing many filters to some classes from multiple layers, and then inactivate them all to validate corresponding impacts.
The experts are also attracted by two mini-sets (d1 and e1 in Fig.~\ref{fig:teaser}), because of their abnormal color patterns.
The filters in these two mini-sets exhibit large changes all the time in the latter part of the training, which are very different from the other anomaly filters.
Thus, the experts are interested in these filters and further check their correlated classes in the Correlation View (right).
Interestingly, each abnormal mini-set only appears with two classes (d2 and e2 in Fig.~\ref{fig:teaser}), and each pair of classes have very similar performances displayed in the Validation View (d3 and e3 in Fig.~\ref{fig:teaser}).
By checking the detailed images of these classes, the experts discover some common patterns.
For example, for mini-set e1, the corresponding classes are about mushrooms growing on grass and dogs playing on grass (e3 in Fig.~\ref{fig:teaser}).
For mini-set d1, the corresponding classes are related to curved shapes, such as parachutes and round textures (d3 in Fig.~\ref{fig:teaser}).
Although the experts are still unclear about why these two mini-sets have such a special behavior, they believe that these filters are likely to play important roles in identifying middle-level features such as grass and curved shapes.
We also conduct further experiments to validate the impact of inactivating these filters and the results are similar to the previous case (i.e., important filters for a class).
After several iterations of refinement, the experts were happy with the current version. They all praised our way of effectively exploring such extreme large-scale training log via a hierarchical manner.
\ea and \eb mentioned that the well-designed validation and layer views were very intuitive and helped them greatly. For example, the layer view allowing the experts to effectively observe and compare layer-related information (e.g., weight/gradient distribution) can help them diagnose network structures. The detecting of dying-ReLU problem in the early stage of a training is useful for tuning the hyper-parameters (e.g., learning rate). This kind of knowledge can also be leveraged to conduct model compression~\cite{han2015deep}, so as to improve the model in respect to computing speed and memory cost. Although the experts still cannot figure out the exact reason that some filters are always more actively updated in the later training stages, they believe the insight that would be obtained from the future investigation will be helpful in diagnosing and improving network structures. Besides, the divergent evolving patterns of classes and the numerous anomaly iterations found in validation view provide the experts with a new promising direction to train a better model.
Both \ea and \ec were particularly fond of the cube-style visualization and deemed it as a new perspective to observe the training of CNNs for them.
They both have found many interesting patterns with the cube visualization, some of which were reasonable or could be explained after thinking for a while.
However, the experts also failed to figure out some other patterns, notwithstanding they conducted several testing experiments.
Nevertheless, they were still excited that our system can help them identify potential subjects for further study.}%it was a pleasant surprise and useful for examining the complex relationships between neuron weights and class performance. He was excited to %and it is really a new perspective to supervise a CNN training process.%using \name, some of which were reasonable or could be explained after thinking for a while. %These patterns are of great value for debugging and optimizing the network. In particular, .%However, some other patterns were quite unexpected, and the experts failed to understand or even form hypotheses for them. Nevertheless, they they were still excited that our system can help them identify potential subjects to further study.%Although the experts wished \name could help them more with these unexpected patterns, they were still excited that our system can help them identify potential subjects to further study. %In general, all the three experts confirmed the effectiveness of \name to facilitate them in debugging and optimizing a CNN during the training process. In particular, \ea thought that the system had great potential in the direction of model compression~\cite{han2015deep} a large CNN.%\td{TODO: add more details - zhuangjiabeishu}%Nevertheless, they still provide several suggestions, for example, \eb thought that it would be better to allow hiding unrelated layers in validation view by interacting with the network graph. \ec suggested to combine some feature oriented visualization methods to enable the exploration of identified anomaly filters from other perspectives.\textbf{Generality} During the implementation, we were concerned about the generality of \name, that is, whether the design was biased to the specific requirements from these three experts.
Therefore, to check how our system is accepted by broader expert communities, we presented our system in a workshop, which involved about 20 experts in the machine learning and visualization fields.
In addition, we also interviewed another group of twelve experts, who worked on a large project about using CNNs to improve image search quality.
We presented the latest version of \name to the experts, encouraged them to experiment with the system, and collected their feedback in the process.
Exceeding our expectation, \name was well accepted by these experts.
Although they proposed several new requirements, the experts shared many major interests with our three collaborators, such as tracking class level performance, filter-level information, and the relationships between them.
After introducing our system, they immediately understood the purposes of each view and all appreciated this novel, intuitive, and expressive way to watch training processes.
Although the demo was performed on our experiment datasets, the experts saw its potential in their project and immediately asked for collaboration with us, so that they could plug in and analyze their own datasets.
For example, two experts suggested that our current system only differentiates correct or incorrect classifications for validation images (i.e., 1 and 0).
However, the exact incorrect labels should also be presented because such information can help identify confusing or similar classes.
One expert mentioned that he showed strong interest on what happens before the anomaly iteration and suggested dump data of every iteration at that abnormal interval for fine-grained analysis.
Another expert suggested that our system shoud be integrated with online dashboards, as visualizing the training log on the fly can allow them to terminate the training early and save time if the visualization shows anything undesired.
Although the experts have high expectations of this tool, we all agree to start with two fundamental pieces of information: neuron weights and validation results.
Considering our target users and the large scale of datasets, we try to avoid using sophisticated visual encodings to ensure a fluent exploration experience.
Unsurprisingly, our bare-to-metal visualizations are preferred by the experts, and they use it to find many patterns easily, either expected or unexpected.
However, we still have several limitations.

First and foremost, although our system can effectively help experts identify strange or interesting patterns, there is still a gap between finding patterns and accelerating CNN training.
The experts still have to reason about and understand what these patterns mean or how to use them to accelerate model training in future.
We think it is not a problem faced just by our system, but by all CNN visualizations in general.
Like previous work, \name may only peel a hole in the box and reveal limited information.
But we hope that, by peeling enough holes, all these strange patterns will start to connect and make sense by themselves, thus providing a clear picture of CNNs.
Our current design can well support showing dozens of layers and classes in the same time. The correlation view shares all the filter strategies with the other two views, and vice versa.
Thus, our system can perform well in most cases.
Nevertheless, the worst scenario still requires to display hundreds or thousands of small multiples at the same time.
A possible solution is to employ task-specific aggregation or filtering methods to show the data of interests.}%\dy{It would be great to see some more numbers regarding the time required for logging and preprocessing when applying the presented solution. In addition, it would be helpful to include a brief discussion of how the different views are affected if more data was included and to which extent the visual representations can scale.}

Third, we propose a rule-based anomaly detection method that requires experts to manually pick a reasonable window size $k$ and set the threshold for filtering. The number and patterns of anomalies are sensitive to these settings. One potential solution to this problem is to develop an automatic method to enumerate all potential parameter settings and identify those can detect a reasonable amount of significant anomalies and provide these settings to the experts as guidance.

Finally, we only conduct experiments on ResNet-50~\cite{he2016deep}, but our method can also be applied to other state-of-the-art deep CNN models, which often have similar hierarchical structures (e.g., ``inception block'' in google-inception-v4~\cite{szegedy2016inception}).
Besides, the cube visualization is a general technique, which can be used to explore multiple heterogeneous time series data and their complex correlations.
However, to further generalize it, a strict user study has to be conducted to find the best manner to use it, such as the axis skew degree, and the minimum height/width for each row/column in the three faces.
}%However, we only provide a general idea to present such complex relationships via 2.5D cube. If we want to apply this idea to a general scenarios, a strict user study has to be carried out to find the best way to use it. For example, the axis skew degree, the minimum height for each row in three faces, etc.}%Furthermore, the interaction methodology used in hierarchical small multiples (i.e., validation view) can also be adopted to solve the visual clutter problem occurred when there are too many small multiples.%\textbf{Usability}%\dy{consider real time use}%\textbf{Future work}. Apart from the aforementioned future work, %As \name is good at tracking important iterations and filters,%another promising direction to the future work can be integrating more feature-oriented visualization techniques. For example, feature visualizations can provide insights on what features a filter in a given snapshot of CNN has learned~\cite{girshick2014rich, zeiler2014visualizing, liu2017towards}. Our system can help track critical iterations to take snapshots for a CNN over training, and then use the feature visualization techniques to analyze the learned features evolving patterns for the detected important filters.%Apart from visualizing more detailed image label information and supporting online analysis (Sec. 8.2), %one more significant work remaining to be completed is to combine \name with some feature-oriented visualization techniques (Sec. 3.1), as \name is complementary for those techniques. In other words, feature-oriented visualization techniques provide .%\name is good at identifying critical training iterations and critical filters and . Thus, the feature visualization techniques can provide auxiliary information.%which focus on disclosing how a given CNN behaves on the input images to understand what features are learned by the CNN. used to disclose how a given CNN behave(Sec.3.1), Because the  There are several directions for future work.  one direction: 1. combine filter activation; 2. image maximally activation - verification%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Conclusion}\label{sec:conclusion}

We propose a novel visual analytics solution to disclose the rich dynamics of CNN training processes. Knowing such information can help machine learning experts better understand, debug, and optimize CNNs. We develop a comprehensive system that mainly comprises the validation, layer, and correlation views to facilitate an interactive exploration of the evolution of image classification results, network parameters, and the correlation between them.
We conduct experiments by training a very deep CNN (ResNet-50) on ImageNet, one of the largest labeled image datasets that is commonly used in practice, to demonstrate the applicability of our system. The positive feedback from our collaborating experts and the experts from an internal workshop validates the usefulness and effectiveness of our system.


Future studies may integrate some feature-oriented visualization techniques, which typically require recording the activation information for input instances. Feature visualizations can provide insights on what features a filter in a given snapshot of CNN has learned. Our system can track critical iterations to take snapshots for a CNN over training, and then use feature visualization techniques to analyze the learned features evolving patterns for the detected important filters. The other urgent need is to deploy the system in a real-time environment. To this end, we have to consider some new design and interaction requirements to fill the gap between finding patterns and accelerating CNN training.%\begin{acks}%%The authors would like to thank Dr. Maura Turolla of Telecom%Italia for providing specifications about the application scenario.%%The work is supported by the \grantsponsor{GS501100001809}{National%  Natural Science Foundation of%  China}{http://dx.doi.org/10.13039/501100001809} under Grant%No.:~\grantnum{GS501100001809}{61273304\_a}%and~\grantnum[http://www.nnsf.cn/youngscientsts]{GS501100001809}{Young%  Scientsts' Support Program}.%%%\end{acks}

\begin{acks}

	The authors would like to thank Kai Yan for providing support in editing the relevant media materials.

	The work is supported by the National Basic Research Program of China (973 program) under Grant No. 2014CB340304
	and ITC Grant with No. UIT/138.


\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{reference}

\end{document}


